{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_on_colab = False\n",
    "if running_on_colab:\n",
    "    \"\"\"cosas para configurar en colab, como mount drive y poner bien los folders de guardado, instalar librerias etc\"\"\"\n",
    "else:\n",
    "    data_folder = \"../../../data/processed/graph_data_nohubs/\"\n",
    "    models_folder = \"../../../data/models/\"\n",
    "    experiments_folder = \"../../../data/experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_sparse import matmul\n",
    "import deepsnap.hetero_gnn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas normalmente irían en otro script .py pero como estamos en un notebook las pongo en esta sección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node_csv(path, index_col,type_col, **kwargs):\n",
    "    \"\"\"Returns node dataframe and a dict of mappings for each node type. \n",
    "    Each mapping maps from original df index to \"heterodata index\" { node_type : { dataframe_index : heterodata_index}}\"\"\"\n",
    "    df = pd.read_csv(path, **kwargs,index_col=index_col)\n",
    "    node_types = df[type_col].unique()\n",
    "    mappings_dict = dict()\n",
    "    for node_type in node_types:\n",
    "        mapping = {index: i for i, index in enumerate(df[df[type_col] == node_type].index.unique())}\n",
    "        mappings_dict[node_type] = mapping\n",
    "\n",
    "    return df,mappings_dict\n",
    "\n",
    "def load_edge_csv(path, src_index_col, dst_index_col, mappings, edge_type_col,src_type_col,dst_type_col, **kwargs):\n",
    "    \"\"\"Returns edge dataframe and a dict of edge indexes. Nodes are indexed according to the \"heterodata index\", using the node mappings from load_node_csv. \n",
    "    Edge indexes are tensors of shape [2, num_edges]. Dict is indexed by triplets of shape (src_type, edge_type, dst_type).\"\"\"\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "    df[\"edge_triple\"] = list(zip(df[src_type_col],df[edge_type_col], df[dst_type_col]))\n",
    "    edge_triplets = df[\"edge_triple\"].unique()\n",
    "\n",
    "    edge_index_dict = dict()\n",
    "    for edge_triplet in edge_triplets:\n",
    "\n",
    "        sub_df = df[df.edge_triple == edge_triplet]\n",
    "        src_type,edge_type,dst_type = edge_triplet\n",
    "\n",
    "        src_mapping = mappings[src_type]\n",
    "        dst_mapping = mappings[dst_type]\n",
    "\n",
    "        src = [src_mapping[index] for index in sub_df[src_index_col]]\n",
    "        dst = [dst_mapping[index] for index in sub_df[dst_index_col]]\n",
    "        edge_index = torch.tensor([src, dst])\n",
    "        edge_index_dict[edge_triplet] = edge_index\n",
    "\n",
    "    return df, edge_index_dict\n",
    "\n",
    "def create_heterodata(node_map, edge_index):\n",
    "    \"\"\"Initializes HeteroData object from torch_geometric and creates corresponding nodes and edges, without any features\"\"\"\n",
    "    data = HeteroData()\n",
    "    for node_type,vals in node_map.items():\n",
    "        # Initialize all node types without features\n",
    "        data[node_type].num_nodes = len(vals)\n",
    "    \n",
    "    for edge_triplet, index in edge_index.items():\n",
    "        src_type, edge_type, dst_type = edge_triplet\n",
    "        data[src_type, edge_type, dst_type].edge_index = index\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_reverse_types(edge_types):\n",
    "    newlist = []\n",
    "    for edge in edge_types:\n",
    "        rev = tuple(reversed(edge))\n",
    "        if rev != edge:\n",
    "            if edge not in newlist:\n",
    "                newlist.append(rev)\n",
    "        else:\n",
    "            newlist.append(rev)\n",
    "\n",
    "    reversed_newlist = [tuple(reversed(edge)) for edge in newlist]\n",
    "\n",
    "    return newlist, reversed_newlist\n",
    "\n",
    "def initialize_features(data_object,feature,dim):\n",
    "    for nodetype, store in data_object.node_items():\n",
    "        if feature == \"random\":\n",
    "            data_object[nodetype].x = torch.rand(store[\"num_nodes\"],dim)\n",
    "        if feature == \"ones\":\n",
    "            data_object[nodetype].x = torch.ones(store[\"num_nodes\"],dim)\n",
    "    return data_object"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del modelo. Como es un prototipo y lo hice para aprender, agregué prints que van describiendo que operaciones está haciendo. Para entrenar, apagar los prints con quiet=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiet = True\n",
    "\n",
    "def talk(msg, quiet=quiet):\n",
    "    if not quiet:\n",
    "        print(msg)\n",
    "\n",
    "def generate_convs(hetero_graph, conv, hidden_size, first_layer=False):\n",
    "    convs = {}\n",
    "\n",
    "    msg_types = hetero_graph.edge_types\n",
    "    for key in msg_types:\n",
    "        if first_layer:\n",
    "            dst_feature_dim = hetero_graph.num_node_features[key[2]]\n",
    "            src_feature_dim = hetero_graph.num_node_features[key[0]]\n",
    "            convs[key] = conv(src_feature_dim, dst_feature_dim, hidden_size)\n",
    "        else:\n",
    "            convs[key] = conv(hidden_size, hidden_size, hidden_size)\n",
    "\n",
    "    return convs\n",
    "\n",
    "def hetero_apply_function(x: dict,func) -> dict:\n",
    "    \"\"\"X es el diccionario de node embeddings o features, {node_type: tensor}.\n",
    "    Aplica func a cada entrada del diccionario, devuelve un dict de la misma forma.\"\"\"\n",
    "    x_transformed = {}\n",
    "    for key,val in x.items():\n",
    "        transformed_val = func(val)\n",
    "        x_transformed[key] = transformed_val\n",
    "    \n",
    "    return x_transformed\n",
    "\n",
    "class HeteroGNNConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels_src, in_channels_dst, out_channels):\n",
    "        super().__init__(aggr=\"mean\")\n",
    "\n",
    "        self.in_channels_src = in_channels_src\n",
    "        self.in_channels_dst = in_channels_dst\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.lin_dst = nn.Linear(in_channels_dst, out_channels)\n",
    "        self.lin_src = nn.Linear(in_channels_src, out_channels)\n",
    "        self.lin_update = nn.Linear(2*out_channels, out_channels)\n",
    "\n",
    "    def forward(self,node_feature_src, node_feature_dst,edge_index):\n",
    "        talk(\"HeteroGNN forward\")\n",
    "        talk(f\"Node feature src shape: {node_feature_src.shape}, Node feature dst shape: {node_feature_dst.shape}, edge index shape: {edge_index.sparse_sizes()}\")\n",
    "        out = self.propagate(edge_index, node_feature_src=node_feature_src,node_feature_dst=node_feature_dst)\n",
    "        return out\n",
    "\n",
    "    def message_and_aggregate(self, edge_index, node_feature_src):\n",
    "        talk(\"HeteroGNN msg and agg\")\n",
    "        talk(f\"node_feature src shape: {node_feature_src.shape}\")\n",
    "        out = matmul(edge_index, node_feature_src, reduce=self.aggr)\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out, node_feature_dst):\n",
    "        talk(\"HeteroGNN update\")\n",
    "        talk(f\"Aggr_out shape: {aggr_out.shape}\")\n",
    "        talk(f\"Dst feature shape: {node_feature_dst.shape}\")\n",
    "        dst_msg = self.lin_dst(node_feature_dst)\n",
    "        src_msg = self.lin_src(aggr_out)\n",
    "\n",
    "        talk(f\"Concat: dst_msg shape: {dst_msg.shape}, src_msg shape: {src_msg.shape}\")\n",
    "        full_msg = torch.concat((dst_msg, src_msg), dim=1)\n",
    "\n",
    "        talk(f\"Full msg shape: {full_msg.shape}\")\n",
    "        out = self.lin_update(full_msg)\n",
    "\n",
    "        talk(f\"After update shape: {out.shape}\")\n",
    "        return out\n",
    "\n",
    "\n",
    "class HeteroGNNWrapperConv(deepsnap.hetero_gnn.HeteroConv):\n",
    "    def __init__(self, convs, aggr=\"mean\"):\n",
    "        super().__init__(convs, None)\n",
    "        self.aggr = aggr\n",
    "\n",
    "        # Map the index and message type\n",
    "        self.mapping = {}\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "\n",
    "    def forward(self, node_features, edge_indices):\n",
    "        talk(\"\\n ------ Wrapper forward ------ \")\n",
    "        message_type_emb = {}\n",
    "\n",
    "        for message_key, adj in edge_indices.items():\n",
    "            talk(f\"\\n{message_key}\\n\")\n",
    "            src_type, edge_type, dst_type = message_key\n",
    "            node_feature_src = node_features[src_type]\n",
    "            node_feature_dst = node_features[dst_type]\n",
    "\n",
    "            message_type_emb[message_key] = self.convs[message_key](node_feature_src,node_feature_dst,adj)\n",
    "\n",
    "        # {dst: [] for src, type, dst in message_type.emb.keys()}\n",
    "        # {tipo de nodo: [lista de embeddings obtenidos]}\n",
    "        node_emb = {dst: [] for _, _, dst in message_type_emb.keys()}\n",
    "        mapping = {}\n",
    "\n",
    "        for (src, edge_type, dst), item in message_type_emb.items():\n",
    "            #esto es para saber que indice es cada terna/msg type\n",
    "            mapping[len(node_emb[dst])] = (src, edge_type, dst)\n",
    "\n",
    "            #Agrego el embedding de la terna (src,type,dst) al la lista de embeddings de dst\n",
    "            node_emb[dst].append(item)\n",
    "\n",
    "        self.mapping = mapping\n",
    "\n",
    "        #Ahora hago aggregation sobre las listas de embeddings, para cada tipo de nodo DST\n",
    "        talk(\"\\n------ Wrapper agg ------\")\n",
    "        for node_type, embs in node_emb.items():\n",
    "            talk(f\"\\nAggregate {node_type} embeddings\")\n",
    "\n",
    "            # Si hay un solo embedding en la lista, me quedo con ese solito\n",
    "            if len(embs) == 1:\n",
    "                talk(f\"Num embeddings = 1, no AGG needed\")\n",
    "                node_emb[node_type] = embs[0]\n",
    "            \n",
    "            #Si hay más de uno hago aggregation\n",
    "            else:\n",
    "                node_emb[node_type] = self.aggregate(embs)\n",
    "        return node_emb\n",
    "\n",
    "    def aggregate(self, xs):\n",
    "        # Tomo la lista de embeddings para cada tipo de nodo y los \"agrego\". En este caso solo los promedio\n",
    "        # Stackeo los embeddings\n",
    "        talk(f\"Num embeddings: {len(xs)}\")\n",
    "        talk(f\"Shape embeddings: {[e.shape for e in xs]}\")\n",
    "        stacked = torch.stack(xs, dim=0)\n",
    "        talk(f\"Stacked shape: {stacked.shape}\")\n",
    "        out = torch.mean(stacked,dim=0)\n",
    "        talk(f\"Final aggregated shape: {out.shape}\")\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hetero_graph, pred_mode, hidden_size=32, aggr=\"mean\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        self.pred_mode = pred_mode\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bns1 = torch.nn.ModuleDict()\n",
    "        self.relus1 = torch.nn.ModuleDict()\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        # if head==\"distmult\":\n",
    "        #   self.distmult_head = distmult_head(hetero_graph,self.hidden_size)\n",
    "\n",
    "        convs1 = generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=True)\n",
    "        convs2 = generate_convs(hetero_graph, HeteroGNNConv, self.hidden_size, first_layer=False)\n",
    "        self.convs1 = HeteroGNNWrapperConv(convs1, aggr=self.aggr)\n",
    "        self.convs2 = HeteroGNNWrapperConv(convs2, aggr=self.aggr)\n",
    "        for node_type in hetero_graph.node_types:\n",
    "            self.bns1[node_type] = torch.nn.BatchNorm1d(self.hidden_size)\n",
    "            self.relus1[node_type] = torch.nn.LeakyReLU()\n",
    "    \n",
    "    def encode(self,graph):\n",
    "        talk(\" ------ ENCODER ------ \")\n",
    "        x = {k:v[\"x\"] for (k,v) in graph.node_items()}\n",
    "        adj = {k:v[\"adj_t\"] for (k,v) in graph.edge_items()}\n",
    "        \n",
    "        talk(\"Conv 1\")\n",
    "        x = self.convs1(x, edge_indices=adj)\n",
    "\n",
    "        talk(\"\\n BNS 1\")\n",
    "        x = deepsnap.hetero_gnn.forward_op(x, self.bns1)\n",
    "\n",
    "        talk(\"\\n Relu 1\")\n",
    "        x = deepsnap.hetero_gnn.forward_op(x, self.relus1)\n",
    "\n",
    "        talk(\"\\n Conv 2\")\n",
    "        x = self.convs2(x, edge_indices=adj)\n",
    "\n",
    "        talk(\"\\n----------\")\n",
    "        talk(f\"Node embeddings done. Dimentions: {[(k,item.shape) for k,item in x.items()]}\")\n",
    "        talk(\"---------\")\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def decode_train(self,x,graph):\n",
    "        supervision_types = [item[0] for item in graph.edge_items() if \"edge_label_index\" in item[1].keys()]\n",
    "        edge_label_index = {k:v[\"edge_label_index\"] for (k,v) in graph.edge_items() if k in supervision_types}\n",
    "\n",
    "        talk(\"\\n ------ DECODER ------ \")\n",
    "        pred = {}\n",
    "        if self.pred_mode == \"all\":\n",
    "            for message_type, edge_index in edge_label_index.items():\n",
    "                talk(f\"\\n Decoding edge type: {message_type}\")\n",
    "                src_type = message_type[0]\n",
    "                trg_type = message_type[2]\n",
    "\n",
    "                x_source = x[src_type]\n",
    "                x_target = x[trg_type]\n",
    "\n",
    "                nodes_src = x_source[edge_index[0]]\n",
    "                nodes_trg = x_target[edge_index[1]]\n",
    "\n",
    "                talk(f\"\\n Multiplying shapes: {nodes_src.shape}, {nodes_trg.shape}\")\n",
    "                pred[message_type] = torch.sum(nodes_src * nodes_trg, dim=-1)\n",
    "\n",
    "        elif self.pred_mode == \"gda_only\":\n",
    "            keys = [edge for edge in supervision_types if \"gda\" in edge]\n",
    "            for message_type in keys:\n",
    "                talk(f\"\\n Decoding edge type: {message_type}\")\n",
    "                edge_index = edge_label_index[message_type]\n",
    "                src_type = message_type[0]\n",
    "                trg_type = message_type[2]\n",
    "\n",
    "                x_source = x[src_type]\n",
    "                x_target = x[trg_type]\n",
    "\n",
    "                nodes_src = x_source[edge_index[0]]\n",
    "                nodes_trg = x_target[edge_index[1]]\n",
    "                talk(f\"\\n Multiplying shapes: {nodes_src.shape}, {nodes_trg.shape}\")\n",
    "                pred[message_type] = torch.sum(nodes_src * nodes_trg, dim=-1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def decode_pred(self,x1,x2):\n",
    "        talk(f\"\\n Multiplying shapes: {x1.shape}, {x2.shape}\")\n",
    "        pred_adj = torch.matmul(x1, x2.t())\n",
    "        pred_adj = torch.sigmoid(pred_adj)\n",
    "\n",
    "        return pred_adj\n",
    "\n",
    "    def forward(self, graph):\n",
    "        x = self.encode(graph)\n",
    "        pred = self.decode_train(x,graph)\n",
    "        \n",
    "        return pred\n",
    "          \n",
    "    def loss(self, prediction_dict, ground_truth_dict):\n",
    "        loss = 0\n",
    "        num_types = len(prediction_dict.keys())\n",
    "        # sets = torch.tensor(len(pred.keys()))\n",
    "        for edge_type,pred in prediction_dict.items():\n",
    "            y = ground_truth_dict[edge_type]\n",
    "            loss += self.loss_fn(pred, y.type(pred.dtype))\n",
    "        return loss/num_types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def hits_at_k(y_true,x_prob,k,key) -> dict:\n",
    "    \"\"\"Dados los tensores x_prob y edge_label, calcula cuantas predicciones hizo correctamente en los primeros k puntajes.\n",
    "    x_prob es la predicción del modelo luego de aplicar sigmoid (sin redondear, osea, el puntaje crudo)\"\"\"\n",
    "\n",
    "    #ordeno los puntajes de mayor a menor\n",
    "    x_prob, indices = torch.sort(x_prob, descending=True)\n",
    "\n",
    "    #me quedo solo con los k mayor punteados\n",
    "    x_prob = x_prob[:k]\n",
    "    indices = indices[:k]\n",
    "\n",
    "    if any(x_prob < 0.5):\n",
    "      threshold_index = (x_prob < 0.5).nonzero()[0].item()\n",
    "      print(f\"Top {k} scores for {key} below classification threshold 0.5, threshold index: {threshold_index}\")\n",
    "\n",
    "    #busco que label tenían esas k preds\n",
    "    labels = y_true[indices]\n",
    "\n",
    "    #cuento cuantas veces predije uno positivo en el top k\n",
    "    hits = labels.sum().item()\n",
    "\n",
    "    return hits\n",
    "\n",
    "def train(model, optimizer, graph, printb):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(graph) # acá no paso por sigmoid porque mi loss_fn es BCE with logits, que aplica sigmoid internamente!\n",
    "    edge_label = {k:v[\"edge_label\"] for (k,v) in graph.edge_items() if \"edge_label\" in v.keys()}\n",
    "    loss = model.loss(preds, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if printb:\n",
    "        print(loss.item())\n",
    "    return loss.item()\n",
    "\n",
    "def get_metrics(y_true, x_pred):\n",
    "   acc = round(accuracy_score(y_true,x_pred),2)\n",
    "   ap = round(average_precision_score(y_true, x_pred),2)\n",
    "   roc_auc = round(roc_auc_score(y_true,x_pred),2)\n",
    "\n",
    "   return acc,ap ,roc_auc\n",
    "  \n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model,data,metric):\n",
    "  model.eval()\n",
    "  preds = model(data)\n",
    "  edge_label = {k:v[\"edge_label\"] for (k,v) in data.edge_items() if \"edge_label\" in v.keys()}\n",
    "  all_preds = []\n",
    "  all_true = []\n",
    "  for key,pred in preds.items():\n",
    "      probabilities = torch.sigmoid(pred)\n",
    "      pred_label = torch.round(probabilities)\n",
    "      ground_truth = edge_label[key]\n",
    "      all_preds.append(pred_label)\n",
    "      all_true.append(ground_truth)\n",
    "  total_predictions = torch.cat(all_preds, dim=0)\n",
    "  total_true = torch.cat(all_true, dim=0)\n",
    "  score = metric(total_true,total_predictions)\n",
    "  return score\n",
    "  \n",
    "\n",
    "@torch.no_grad()\n",
    "def full_test(model,data,k,global_score=True):\n",
    "  model.eval()\n",
    "  preds = model(data)\n",
    "  edge_label = {k:v[\"edge_label\"] for (k,v) in data.edge_items() if \"edge_label\" in v.keys()}\n",
    "  metrics = {}\n",
    "\n",
    "  if global_score:\n",
    "    all_scores = []\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    for key,pred in preds.items():\n",
    "        probabilities = torch.sigmoid(pred)\n",
    "        pred_label = torch.round(probabilities)\n",
    "        ground_truth = edge_label[key]\n",
    "        all_scores.append(probabilities)\n",
    "        all_preds.append(pred_label)\n",
    "        all_true.append(ground_truth)\n",
    "\n",
    "    total_predictions = torch.cat(all_preds, dim=0)\n",
    "    total_true = torch.cat(all_true, dim=0)\n",
    "    total_scores = torch.cat(all_scores,dim=0)\n",
    "\n",
    "    acc, ap, roc_auc =  get_metrics(total_true, total_predictions)\n",
    "    hits_k = hits_at_k(total_true,total_scores,k,\"all\")\n",
    "    metrics[\"all\"] = [acc,ap,roc_auc,hits_k]\n",
    "\n",
    "  else:\n",
    "    for key,pred in preds.items():\n",
    "        probabilities = torch.sigmoid(pred)\n",
    "        pred_label = torch.round(probabilities)\n",
    "        ground_truth = edge_label[key]\n",
    "        acc, ap, roc_auc = get_metrics(ground_truth, pred_label)\n",
    "        hits_k = hits_at_k(ground_truth,probabilities,k,key)\n",
    "        metrics[key] = [acc,ap, roc_auc,hits_k]\n",
    "  \n",
    "  return metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data from csv and create heterodata object\n",
    "node_data, node_map = load_node_csv(data_folder+\"nohub_graph_nodes.csv\",\"node_index\",\"node_type\")\n",
    "edge_data, edge_index = load_edge_csv(data_folder+\"nohub_graph_edge_data.csv\",\"x_index\",\"y_index\",node_map,\"edge_type\",\"x_type\",\"y_type\")\n",
    "data = create_heterodata(node_map,edge_index)\n",
    "\n",
    "#Split the dataset\n",
    "edge_types, rev_edge_types = get_reverse_types(data.edge_types)\n",
    "data = initialize_features(data,\"random\",10)\n",
    "split_transform = T.RandomLinkSplit(num_val=0.3, num_test=0.3, is_undirected=True, add_negative_train_samples=True, disjoint_train_ratio=0.2,edge_types=edge_types,rev_edge_types=rev_edge_types)\n",
    "transform_dataset = T.Compose([split_transform, T.ToSparseTensor(remove_edge_index=False),T.ToDevice(device)])\n",
    "\n",
    "train_data, val_data, test_data = transform_dataset(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un solo tipo de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_stats(title, losses, train_metric,val_metric,metric_str):\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax2 = ax.twinx()\n",
    "\n",
    "  ax.set_xlabel(\"Training Epochs\")\n",
    "  ax2.set_ylabel(\"Performance Metric\")\n",
    "  ax.set_ylabel(\"Loss\")\n",
    "\n",
    "  plt.title(title)\n",
    "  p1, = ax.plot(losses, \"b-\", label=\"training loss\")\n",
    "  p2, = ax2.plot(val_metric, \"r-\", label=f\"val {metric_str}\")\n",
    "  p3, = ax2.plot(train_metric, \"o-\", label=f\"train {metric_str}\")\n",
    "  plt.legend(handles=[p1, p2, p3])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'hidden_size': 32,\n",
    "    'weight_decay': 1e-5,\n",
    "    'lr': 0.01,\n",
    "    'epochs':50,\n",
    "}\n",
    "\n",
    "model = HeteroGNN(data,\"all\",args[\"hidden_size\"],\"mean\").to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6973788142204285\n",
      "0.4353945255279541\n",
      "0.35876742005348206\n",
      "0.3058912754058838\n",
      "0.3494686186313629\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "metric = accuracy_score\n",
    "metric_name = \"Global accuracy\"\n",
    "\n",
    "for epoch in range(args[\"epochs\"]):\n",
    "    if epoch%10 == 0:\n",
    "        printb = True\n",
    "    else:\n",
    "        printb = False\n",
    "\n",
    "    loss = train(model,optimizer,train_data,printb)\n",
    "    train_score = test(model,train_data,metric)\n",
    "    val_score = test(model,val_data,metric)\n",
    "    losses.append(loss)\n",
    "    train_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "\n",
    "plot_training_stats(\"GraphSAGE prototype training stats\",losses,train_scores,val_scores,metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 200 scores for ('bert_group', 'disease_disease', 'bert_group') below classification threshold 0.5, threshold index: 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('gene_protein', 'ppi', 'gene_protein'): [0.64, 0.58, 0.64, 200.0],\n",
       " ('gene_protein', 'gda', 'disease'): [0.7, 0.63, 0.7, 150.0],\n",
       " ('gene_protein', 'pathway_protein', 'pathway'): [0.75, 0.68, 0.75, 197.0],\n",
       " ('disease', 'disease_disease', 'disease'): [0.6, 0.56, 0.6, 156.0],\n",
       " ('gene_protein', 'form_complex', 'complex'): [0.67, 0.61, 0.67, 150.0],\n",
       " ('disease', 'disease_disease', 'bert_group'): [0.52, 0.51, 0.52, 106.0],\n",
       " ('bert_group', 'disease_disease', 'bert_group'): [0.46, 0.48, 0.46, 96.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test(model,test_data,200,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperparameter_search(param_grid, train_set, val_set, save_weights=False, early_stop=False):\n",
    "  default = {\n",
    "      'hidden_size': [32],\n",
    "      'weight_decay': [1e-5],\n",
    "      'lr': [0.01],\n",
    "      'max_epochs':[10],\n",
    "      \"aggr\":[\"mean\"],\n",
    "      \"num_features\":[10],\n",
    "      \"feature_type\":[\"random\"],\n",
    "      \"pred_mode\":[\"gda_only\"]\n",
    "  }\n",
    "\n",
    "  for arg in default:\n",
    "    if arg not in param_grid:\n",
    "      param_grid[arg] = default[arg]\n",
    "\n",
    "  grid = ParameterGrid(param_grid)\n",
    "  auc_results = {}\n",
    "  auc_results_2 = []\n",
    "  best_model = None\n",
    "  best_model_eid = 0\n",
    "\n",
    "  eid = 0 # experiment id\n",
    "  for params in grid:\n",
    "    # Index of the model, represents the parameters\n",
    "    index = '; '.join(x + '_' + str(y) for x, y in params.items())\n",
    "    print(index)\n",
    "\n",
    "    # Launch a training experiment using the current set of parameters\n",
    "    val_auc,current_model = launch_experiment(eid,\n",
    "                   params,\n",
    "                   train_set,\n",
    "                   val_set,\n",
    "                   save_weights=save_weights,\n",
    "                   early_stop=early_stop)\n",
    "    \n",
    "    auc_results[index] = val_auc\n",
    "    params[\"auc\"] = val_auc\n",
    "    auc_results_2.append(params)\n",
    "\n",
    "    if max(auc_results, key = auc_results.get) == index:\n",
    "      best_model = current_model\n",
    "      best_model_eid = eid\n",
    "    eid += 1\n",
    "\n",
    "    print(f\"Validation AUC: {round(val_auc,2)}. Iteration: {eid} of {grid.__len__()}\")\n",
    "\n",
    "  # Select the best results\n",
    "  best_auc_model_params = grid[best_model_eid]\n",
    "\n",
    "  return best_auc_model_params, best_model, auc_results_2\n",
    "\n",
    "def launch_experiment(eid, params, train_set, val_set, save_weights=False, early_stop=False):\n",
    "  \n",
    "  # Construct the features to be used.\n",
    "  train_set = initialize_features(train_set,params[\"feature_type\"],params[\"num_features\"])\n",
    "  val_set = initialize_features(val_set,params[\"feature_type\"],params[\"num_features\"])\n",
    "\n",
    "\n",
    "  #Initialize model\n",
    "  model = HeteroGNN(train_set,params[\"pred_mode\"],params[\"hidden_size\"],params[\"aggr\"])\n",
    "\n",
    "  model = model.to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params[\"weight_decay\"])\n",
    "\n",
    "  prev_train_loss = 0.1 # Set to a small non-zero value\n",
    "  for epoch in range(params['max_epochs']):\n",
    "    train_loss = train(model,optimizer,train_set,False)\n",
    "    val_auc = test(model,val_set,roc_auc_score)\n",
    "\n",
    "    # we can also add logic here to save the weights of the model if this current epoch \n",
    "    # gives the best performance so far. Mostly passing in eid to construct a filename\n",
    "    # for saving the model weights.\n",
    "\n",
    "    if early_stop:\n",
    "      loss_delta = abs(train_loss - prev_train_loss)\n",
    "      # Stop criteria:\n",
    "      # loss changing <10% from previous epoch\n",
    "      # we can also add a criteria like\n",
    "      # validation ap less than train ap by more than 0.3.\n",
    "      # the second criteria suggests the gap is large between train/valid results\n",
    "      # meaning we could be overfitting if we continue.\n",
    "      if loss_delta / prev_train_loss < 0.1:\n",
    "        break\n",
    "\n",
    "  return val_auc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggr_mean; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.81. Iteration: 1 of 24\n",
      "aggr_mean; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.8. Iteration: 2 of 24\n",
      "aggr_mean; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.78. Iteration: 3 of 24\n",
      "aggr_mean; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.79. Iteration: 4 of 24\n",
      "aggr_mean; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.8. Iteration: 5 of 24\n",
      "aggr_mean; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.82. Iteration: 6 of 24\n",
      "aggr_mean; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.81. Iteration: 7 of 24\n",
      "aggr_mean; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.79. Iteration: 8 of 24\n",
      "aggr_max; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.81. Iteration: 9 of 24\n",
      "aggr_max; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.81. Iteration: 10 of 24\n",
      "aggr_max; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.8. Iteration: 11 of 24\n",
      "aggr_max; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.79. Iteration: 12 of 24\n",
      "aggr_max; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.78. Iteration: 13 of 24\n",
      "aggr_max; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.81. Iteration: 14 of 24\n",
      "aggr_max; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.78. Iteration: 15 of 24\n",
      "aggr_max; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.59. Iteration: 16 of 24\n",
      "aggr_sum; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.8. Iteration: 17 of 24\n",
      "aggr_sum; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.81. Iteration: 18 of 24\n",
      "aggr_sum; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.79. Iteration: 19 of 24\n",
      "aggr_sum; feature_type_random; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.78. Iteration: 20 of 24\n",
      "aggr_sum; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.78. Iteration: 21 of 24\n",
      "aggr_sum; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_50; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.65. Iteration: 22 of 24\n",
      "aggr_sum; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_1e-05\n",
      "Validation AUC: 0.8. Iteration: 23 of 24\n",
      "aggr_sum; feature_type_ones; hidden_size_32; lr_0.01; max_epochs_10; num_features_100; pred_mode_gda_only; weight_decay_0\n",
      "Validation AUC: 0.82. Iteration: 24 of 24\n",
      "Best AUC Model: {'weight_decay': 0, 'pred_mode': 'gda_only', 'num_features': 100, 'max_epochs': 10, 'lr': 0.01, 'hidden_size': 32, 'feature_type': 'ones', 'aggr': 'sum'}\n"
     ]
    }
   ],
   "source": [
    "# parameters = {\n",
    "#     'hidden_size': [32,64],\n",
    "#     'weight_decay': [1e-5,1e-4,1e-3,0],\n",
    "#     'lr': [0.1,0.01,0.001],\n",
    "#     'max_epochs':[10],\n",
    "#     \"aggr\":[\"mean\",\"max\",\"sum\"],\n",
    "#     \"num_features\":[10,50,100,200],\n",
    "#     \"feature_type\":[\"random\",\"ones\"],\n",
    "#     \"pred_mode\":[\"gda_only\",\"all\"]\n",
    "# }type(best_auc_model_params)\n",
    "\n",
    "parameters = {\n",
    "    'hidden_size': [32],\n",
    "    'weight_decay': [1e-5,0],\n",
    "    'lr': [0.01],\n",
    "    'max_epochs':[10],\n",
    "    \"aggr\":[\"mean\",\"max\",\"sum\"],\n",
    "    \"num_features\":[50,100],\n",
    "    \"feature_type\":[\"random\",\"ones\"],\n",
    "    \"pred_mode\":[\"gda_only\"]\n",
    "}\n",
    "\n",
    "best_auc_model_params, best_model, all_results = perform_hyperparameter_search(parameters, train_data, val_data)\n",
    "print(\"Best AUC Model:\", best_auc_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroGNN(\n",
       "  (bns1): ModuleDict(\n",
       "    (gene_protein): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (disease): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (pathway): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (complex): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bert_group): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relus1): ModuleDict(\n",
       "    (gene_protein): LeakyReLU(negative_slope=0.01)\n",
       "    (disease): LeakyReLU(negative_slope=0.01)\n",
       "    (pathway): LeakyReLU(negative_slope=0.01)\n",
       "    (complex): LeakyReLU(negative_slope=0.01)\n",
       "    (bert_group): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       "  (convs1): HeteroGNNWrapperConv(\n",
       "    (modules): ModuleList(\n",
       "      (0): HeteroGNNConv()\n",
       "      (1): HeteroGNNConv()\n",
       "      (2): HeteroGNNConv()\n",
       "      (3): HeteroGNNConv()\n",
       "      (4): HeteroGNNConv()\n",
       "      (5): HeteroGNNConv()\n",
       "      (6): HeteroGNNConv()\n",
       "      (7): HeteroGNNConv()\n",
       "      (8): HeteroGNNConv()\n",
       "      (9): HeteroGNNConv()\n",
       "      (10): HeteroGNNConv()\n",
       "    )\n",
       "  )\n",
       "  (convs2): HeteroGNNWrapperConv(\n",
       "    (modules): ModuleList(\n",
       "      (0): HeteroGNNConv()\n",
       "      (1): HeteroGNNConv()\n",
       "      (2): HeteroGNNConv()\n",
       "      (3): HeteroGNNConv()\n",
       "      (4): HeteroGNNConv()\n",
       "      (5): HeteroGNNConv()\n",
       "      (6): HeteroGNNConv()\n",
       "      (7): HeteroGNNConv()\n",
       "      (8): HeteroGNNConv()\n",
       "      (9): HeteroGNNConv()\n",
       "      (10): HeteroGNNConv()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = initialize_features(data,best_auc_model_params[\"feature_type\"],best_auc_model_params[\"num_features\"])\n",
    "transform = T.Compose([T.ToSparseTensor(remove_edge_index=False),T.ToDevice(device)])\n",
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prioritize(model,node_index,node_type,gene_encodings,disease_encodings,node_map=node_map,node_data=node_data):\n",
    "    model.eval()\n",
    "\n",
    "    if node_type == \"disease\":\n",
    "        disease_index = node_map[\"disease\"][node_index]\n",
    "        disease_vector = disease_encodings[disease_index]\n",
    "        predicted_edges = model.decode_pred(gene_encodings,disease_vector)\n",
    "        ranked_edges, ranked_indices = torch.sort(predicted_edges, descending=True)\n",
    "        results = pd.DataFrame({\"score\":ranked_edges.numpy(),\"heterodata_index\":ranked_indices.numpy()})\n",
    "        results.score = results.score.round(3)\n",
    "        prediction_dataframe = pd.DataFrame({\"original_index\":node_map[\"gene_protein\"].keys(),\"heterodata_index\":node_map[\"gene_protein\"].values()})\n",
    "\n",
    "    elif node_type == \"gene_protein\":\n",
    "        gene_index = node_map[\"gene_protein\"][node_index]\n",
    "        gene_vector = gene_encodings[gene_index]\n",
    "        predicted_edges = model.decode_pred(disease_encodings,gene_vector)\n",
    "        ranked_edges, ranked_indices = torch.sort(predicted_edges, descending=True)\n",
    "        results = pd.DataFrame({\"score\":ranked_edges.numpy(),\"heterodata_index\":ranked_indices.numpy()})\n",
    "        results.score = results.score.round(3)\n",
    "        prediction_dataframe = pd.DataFrame({\"original_index\":node_map[\"disease\"].keys(),\"heterodata_index\":node_map[\"disease\"].values()})\n",
    "\n",
    "\n",
    "    prediction_dataframe = pd.merge(prediction_dataframe,node_data[\"node_name\"],left_on=\"original_index\",right_index=True)\n",
    "    ranked_predictions = pd.merge(prediction_dataframe,results,left_on=\"heterodata_index\",right_on=\"heterodata_index\").sort_values(by=\"score\",ascending=False).reset_index(drop=True)\n",
    "    ranked_predictions.index.name = \"rank\"\n",
    "\n",
    "    return ranked_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    encodings = best_model.encode(data)\n",
    "    gene_encodings = encodings[\"gene_protein\"]\n",
    "    disease_encodings = encodings[\"disease\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo los encodings para los dos tipos de nodos que me interesan. Si quisiera TODOS los posibles enlaces, directamente hago matmul las dos matrices de embedding.\n",
    "El resultado es una matriz de dimensión n_genes x n_enfermedades. Es algo como una matriz de adyacencia probabilística, cada valor i,j representa la probabilidad de que haya un enlace entre el par de nodos (i,j)\n",
    "Ahora falta mapear los resultados a los nodos y rankearlos como queremos. Podemos mirarlo como un ranking general o pedir el ranking para un gen/enfermedad en particular."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero es una matriz enorme, con millones de elementos. Para obtener el ranking tendría que sortear esto y es muy costoso computacionalmente. Entonces en vez de eso elijo que enfermedades quiero ver (o genes) y hago matmul pero con esa matriz reducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked edges for disease: BLOOD GROUP--WALDNER TYPE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>heterodata_index</th>\n",
       "      <th>node_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8359</td>\n",
       "      <td>14296</td>\n",
       "      <td>MAFA</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9922</td>\n",
       "      <td>13106</td>\n",
       "      <td>MECR</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15458</td>\n",
       "      <td>14954</td>\n",
       "      <td>ASRGL1</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>361</td>\n",
       "      <td>1987</td>\n",
       "      <td>ARFRP1</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2802</td>\n",
       "      <td>4793</td>\n",
       "      <td>SYT9</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17317</th>\n",
       "      <td>13184</td>\n",
       "      <td>9640</td>\n",
       "      <td>MUTED</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17318</th>\n",
       "      <td>1120</td>\n",
       "      <td>3098</td>\n",
       "      <td>AP3M2</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17319</th>\n",
       "      <td>8250</td>\n",
       "      <td>14452</td>\n",
       "      <td>TBPL2</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17320</th>\n",
       "      <td>9946</td>\n",
       "      <td>15383</td>\n",
       "      <td>NAA20</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17321</th>\n",
       "      <td>17693</td>\n",
       "      <td>17124</td>\n",
       "      <td>ZBT47</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17322 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_index  heterodata_index node_name  score\n",
       "rank                                                    \n",
       "0                8359             14296      MAFA  0.989\n",
       "1                9922             13106      MECR  0.989\n",
       "2               15458             14954    ASRGL1  0.989\n",
       "3                 361              1987    ARFRP1  0.989\n",
       "4                2802              4793      SYT9  0.989\n",
       "...               ...               ...       ...    ...\n",
       "17317           13184              9640     MUTED  0.015\n",
       "17318            1120              3098     AP3M2  0.015\n",
       "17319            8250             14452     TBPL2  0.014\n",
       "17320            9946             15383     NAA20  0.014\n",
       "17321           17693             17124     ZBT47  0.013\n",
       "\n",
       "[17322 rows x 4 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_type = \"disease\"\n",
    "demo = node_data[node_data.node_type == node_type].sample(1)\n",
    "node_index = demo.index.values[0]\n",
    "node_name = demo.loc[node_index,\"node_name\"]\n",
    "\n",
    "results = prioritize(model,node_index,node_type,gene_encodings,disease_encodings)\n",
    "print(f\"Ranked edges for {node_type}: {node_name}\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>heterodata_index</th>\n",
       "      <th>node_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13647</th>\n",
       "      <td>8870</td>\n",
       "      <td>3517</td>\n",
       "      <td>SLC4A1</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rank  heterodata_index node_name  score\n",
       "original_index                                         \n",
       "13647           8870              3517    SLC4A1  0.886"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_type = \"disease\" if node_type == \"gene_protein\" else \"gene_protein\"\n",
    "existing_edges = edge_data.loc[(edge_data.x_index == node_index) & (edge_data.y_type == y_type),\"y_index\"].values\n",
    "results.reset_index().set_index(\"original_index\").loc[existing_edges]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save best model weights and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_decay': 0,\n",
       " 'pred_mode': 'gda_only',\n",
       " 'num_features': 100,\n",
       " 'max_epochs': 10,\n",
       " 'lr': 0.01,\n",
       " 'hidden_size': 32,\n",
       " 'feature_type': 'ones',\n",
       " 'aggr': 'sum'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_auc_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,param_dict,folder_path,model_name):\n",
    "    date = datetime.datetime.now()\n",
    "    fdate = date.strftime(\"%d_%m_%y__%I_%M\")\n",
    "    fname = f\"{model_name}_{fdate}\"\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{folder_path}{fname}.pth\")\n",
    "\n",
    "    with open(f\"{folder_path}params_{fname}.pickle\", 'wb') as handle:\n",
    "        pickle.dump(param_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(best_model,best_auc_model_params,models_folder,\"graphsage_prototype_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(file_name,file_folder):\n",
    "    params_path = f\"{file_folder}params_{file_name}.pickle\"\n",
    "    state_dict_path = f\"{file_folder}{file_name}.pth\"\n",
    "\n",
    "    state_dict = torch.load(state_dict_path)\n",
    "\n",
    "    with open(params_path, 'rb') as handle:\n",
    "        params = pickle.load(handle)\n",
    "    \n",
    "    return state_dict, params\n",
    "\n",
    "def load_HeteroGNN(state_dict,params,data):\n",
    "    data = initialize_features(data,params[\"feature_type\"],params[\"num_features\"])\n",
    "    model = HeteroGNN(data,params[\"pred_mode\"],params[\"hidden_size\"],params[\"aggr\"])\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"graphsage_prototype_best_31_03_23__01_19\"\n",
    "state_dict, params = load_model_data(model_name,models_folder)\n",
    "saved_model, new_data = load_HeteroGNN(state_dict,params,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    saved_model.eval()\n",
    "    new_encodings = saved_model.encode(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gene_protein': tensor([[ 0.0239,  0.0208, -0.2280,  ...,  0.4040, -0.0263, -0.0583],\n",
       "         [-0.1726, -0.1393, -0.3212,  ...,  0.1179,  0.1834, -0.0242],\n",
       "         [ 0.0547,  0.0228, -0.2313,  ...,  0.4395, -0.0222, -0.0631],\n",
       "         ...,\n",
       "         [-0.2098, -0.1425, -0.3507,  ...,  0.0945,  0.2245, -0.0459],\n",
       "         [ 0.0118,  0.0559, -0.2165,  ...,  0.4412, -0.0156, -0.0815],\n",
       "         [ 0.0011,  0.0313, -0.2675,  ...,  0.3687, -0.0307, -0.0664]]),\n",
       " 'disease': tensor([[ 0.0730, -0.0022, -0.0235,  ...,  0.1237,  0.0491, -0.0309],\n",
       "         [-0.0434, -0.0764, -0.0974,  ...,  0.1828,  0.1271,  0.0007],\n",
       "         [-0.0509,  0.0547, -0.1454,  ...,  0.2979,  0.1364, -0.1076],\n",
       "         ...,\n",
       "         [ 0.1884,  0.1128,  0.1976,  ..., -0.0930,  0.1157,  0.0733],\n",
       "         [ 0.1934,  0.1529,  0.2694,  ..., -0.1473,  0.1051,  0.0885],\n",
       "         [ 0.1844,  0.1006,  0.2357,  ..., -0.1327,  0.0924,  0.0670]]),\n",
       " 'pathway': tensor([[-0.1262, -0.0067,  0.1201,  ...,  0.3113, -0.0086, -0.0949],\n",
       "         [-0.1471,  0.0085,  0.1543,  ...,  0.3562, -0.0296, -0.1171],\n",
       "         [-0.1483,  0.0473,  0.1205,  ...,  0.3347, -0.0525, -0.1853],\n",
       "         ...,\n",
       "         [-0.0977,  0.0258,  0.1148,  ...,  0.3462, -0.0356, -0.1447],\n",
       "         [-0.0770,  0.0776,  0.1162,  ...,  0.2940, -0.0291, -0.1460],\n",
       "         [-0.1067, -0.0012,  0.1363,  ...,  0.3540, -0.0028, -0.1183]]),\n",
       " 'complex': tensor([[ 0.0483,  0.1334,  0.0394,  ...,  0.3055,  0.1310,  0.1456],\n",
       "         [-0.0388,  0.1498, -0.0490,  ...,  0.2616,  0.1629,  0.1391],\n",
       "         [-0.0041,  0.1219,  0.0026,  ...,  0.2820,  0.1742,  0.1143],\n",
       "         ...,\n",
       "         [-0.0750,  0.1440, -0.0135,  ...,  0.2257,  0.1179,  0.1597],\n",
       "         [-0.0866,  0.1203, -0.0290,  ...,  0.2599,  0.1470,  0.1776],\n",
       "         [-0.1834,  0.1496, -0.0848,  ...,  0.2208,  0.1395,  0.2149]]),\n",
       " 'bert_group': tensor([[-0.0338,  0.1684, -0.0220,  ..., -0.0499, -0.0085, -0.0812],\n",
       "         [-0.0087,  0.1411, -0.0697,  ...,  0.0255, -0.0394, -0.0379],\n",
       "         [ 0.0143,  0.1309, -0.1072,  ...,  0.0378, -0.0217, -0.0345],\n",
       "         ...,\n",
       "         [ 0.0349,  0.1162, -0.0132,  ..., -0.0187, -0.0396, -0.0622],\n",
       "         [ 0.0405,  0.1083, -0.0567,  ..., -0.0156, -0.0124, -0.0414],\n",
       "         [ 0.0314,  0.1297, -0.0352,  ..., -0.0223, -0.0125, -0.0486]])}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = pd.DataFrame(all_results)\n",
    "experiment_results.to_csv(experiments_folder+\"graphsage_prototype.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggr</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>max_epochs</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pred_mode</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sum</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.815525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.815386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sum</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.814057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mean</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.809375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.808602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.807193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.806856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.806380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sum</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.804178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sum</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.799794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.798524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.795767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.795548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.792057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.791839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.790569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sum</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.785947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sum</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.784935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.779797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.778726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.777932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sum</td>\n",
       "      <td>random</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.776781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sum</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.646544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max</td>\n",
       "      <td>ones</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>gda_only</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.590799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aggr feature_type  hidden_size    lr  max_epochs  num_features pred_mode  \\\n",
       "23   sum         ones           32  0.01          10           100  gda_only   \n",
       "5   mean         ones           32  0.01          10            50  gda_only   \n",
       "17   sum       random           32  0.01          10            50  gda_only   \n",
       "6   mean         ones           32  0.01          10           100  gda_only   \n",
       "9    max       random           32  0.01          10            50  gda_only   \n",
       "0   mean       random           32  0.01          10            50  gda_only   \n",
       "13   max         ones           32  0.01          10            50  gda_only   \n",
       "8    max       random           32  0.01          10            50  gda_only   \n",
       "16   sum       random           32  0.01          10            50  gda_only   \n",
       "22   sum         ones           32  0.01          10           100  gda_only   \n",
       "10   max       random           32  0.01          10           100  gda_only   \n",
       "1   mean       random           32  0.01          10            50  gda_only   \n",
       "4   mean         ones           32  0.01          10            50  gda_only   \n",
       "7   mean         ones           32  0.01          10           100  gda_only   \n",
       "11   max       random           32  0.01          10           100  gda_only   \n",
       "3   mean       random           32  0.01          10           100  gda_only   \n",
       "18   sum       random           32  0.01          10           100  gda_only   \n",
       "20   sum         ones           32  0.01          10            50  gda_only   \n",
       "2   mean       random           32  0.01          10           100  gda_only   \n",
       "14   max         ones           32  0.01          10           100  gda_only   \n",
       "12   max         ones           32  0.01          10            50  gda_only   \n",
       "19   sum       random           32  0.01          10           100  gda_only   \n",
       "21   sum         ones           32  0.01          10            50  gda_only   \n",
       "15   max         ones           32  0.01          10           100  gda_only   \n",
       "\n",
       "    weight_decay       auc  \n",
       "23       0.00000  0.815525  \n",
       "5        0.00000  0.815386  \n",
       "17       0.00000  0.814057  \n",
       "6        0.00001  0.809375  \n",
       "9        0.00000  0.808602  \n",
       "0        0.00001  0.807193  \n",
       "13       0.00000  0.806856  \n",
       "8        0.00001  0.806380  \n",
       "16       0.00001  0.804178  \n",
       "22       0.00001  0.799794  \n",
       "10       0.00001  0.798524  \n",
       "1        0.00000  0.795767  \n",
       "4        0.00001  0.795548  \n",
       "7        0.00000  0.792057  \n",
       "11       0.00000  0.791839  \n",
       "3        0.00000  0.790569  \n",
       "18       0.00001  0.785947  \n",
       "20       0.00001  0.784935  \n",
       "2        0.00001  0.779797  \n",
       "14       0.00001  0.778726  \n",
       "12       0.00001  0.777932  \n",
       "19       0.00000  0.776781  \n",
       "21       0.00000  0.646544  \n",
       "15       0.00000  0.590799  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results.sort_values(by=\"auc\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
