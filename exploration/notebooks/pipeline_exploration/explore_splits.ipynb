{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23328"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param_grid = {\n",
    "    \"hidden_channels\": [32, 64],\n",
    "    \"micro_aggregation\": [\"mean\", \"sum\", \"max\"],\n",
    "    \"macro_aggregation\": [\"mean\", \"sum\", \"max\"],\n",
    "    \"layer_connectivity\": [None, \"skipsum\"],\n",
    "    \"L2_norm\": [True, False],\n",
    "    \"pre_process_layers\": [0, 1, 2],\n",
    "    \"msg_passing_layers\": [2, 3, 4],\n",
    "    \"post_process_layers\": [0, 1, 2],\n",
    "    \"normalize_output\": [False, True],\n",
    "    \"jumping_knowledge\": [True, False],\n",
    "    \"feature_dim\": [16, 32, 64],\n",
    "}\n",
    "import numpy as np\n",
    "np.prod([len(vals) for vals in model_param_grid.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "from src.models import training_utils\n",
    "\n",
    "data_folder = \"../../../data/processed/graph_data_nohubs/merged_types/\"\n",
    "experiments_folder = \"../../../data/experiments/design_space_merged_experiment/seed_0/\"\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo splits hechos con random link split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_csv = pd.read_csv(data_folder+\"merged_nodes.csv\", index_col=\"node_index\")\n",
    "node_info = pd.read_csv(data_folder+\"merged_node_info.csv\",index_col=0)\n",
    "edge_data = pd.read_csv(data_folder+\"merged_edges.csv\")\n",
    "\n",
    "datasets, node_map = training_utils.load_data(data_folder+\"split_dataset/seed_0/\")\n",
    "train_data,val_data = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_index_df(node_data, node_map, node_info):\n",
    "    sub_dfs = []\n",
    "    for node_type in node_map.keys():\n",
    "        sub_df = node_data[node_data.node_type == node_type]\n",
    "        node_map_series = pd.Series(node_map[node_type], name=\"tensor_index\")\n",
    "        sub_df = sub_df.merge(node_map_series, left_on=\"node_index\", right_index=True,\n",
    "                              how=\"right\").sort_values(by=\"tensor_index\").reset_index()\n",
    "\n",
    "        sub_dfs.append(sub_df)\n",
    "    tensor_df = pd.concat(sub_dfs, ignore_index=True)\n",
    "    df = pd.merge(tensor_df, node_info[[\"node_index\", \"comunidades_infomap\", \"comunidades_louvain\",\n",
    "                  \"degree_gda\", \"degree_pp\", \"degree_dd\"]], on=\"node_index\")\n",
    "    df[\"total_degree\"] = df.degree_pp + df.degree_gda + df.degree_dd\n",
    "    return df\n",
    "\n",
    "def tensor_to_edgelist(tensor: torch.tensor):\n",
    "    sources = tensor[0,:].tolist()\n",
    "    targets = tensor[1,:].tolist()\n",
    "    edgelist = list(zip(sources,targets))\n",
    "    return edgelist\n",
    "\n",
    "def reverse_map(node_map,edge_list,edge_type):\n",
    "    \"\"\"Maps edge dictionary from pyg Heterodata back into the original node indexes from the dataframe\"\"\"\n",
    "    src_map = {v:k for k,v in node_map[edge_type[0]].items()}\n",
    "    dst_map = {v:k for k,v in node_map[edge_type[2]].items()}\n",
    "    mapped_edge_list = [(src_map[n1],dst_map[n2]) for (n1,n2) in edge_list]\n",
    "\n",
    "    return mapped_edge_list\n",
    "\n",
    "def inverse_map_heterodata(data,node_map):\n",
    "    \"\"\"Maps full edge data from pyg Heterodata back into the original node indexes from the dataframe\"\"\"\n",
    "    edge_dict = {}\n",
    "    for edge_type in data.edge_types:\n",
    "        type_dict = {}\n",
    "        edge_tensor = data[edge_type][\"edge_index\"]\n",
    "        edge_list = tensor_to_edgelist(edge_tensor)\n",
    "        mapped_edge_list = reverse_map(node_map,edge_list,edge_type)\n",
    "\n",
    "        type_dict[\"message_passing_edges\"] = mapped_edge_list\n",
    "\n",
    "        if \"edge_label_index\" in data[edge_type].keys():\n",
    "            labeled_edges_tensor = data[edge_type][\"edge_label_index\"]\n",
    "            labeled_edges_list = tensor_to_edgelist(labeled_edges_tensor)\n",
    "            mapped_labeled_edges_list = reverse_map(node_map,labeled_edges_list,edge_type)\n",
    "\n",
    "            edge_labels = data[edge_type][\"edge_label\"].tolist()\n",
    "\n",
    "            type_dict[\"supervision_edges\"] = mapped_labeled_edges_list\n",
    "            type_dict[\"supervision_labels\"] = edge_labels\n",
    " \n",
    "        edge_dict[edge_type] = type_dict\n",
    "    \n",
    "    return edge_dict\n",
    "\n",
    "def edge_map_to_df(inverse_map_dict):\n",
    "    edges_df = {}\n",
    "    for edge_type,sub_dict in inverse_map_dict.items():\n",
    "        if \"supervision_edges\" in sub_dict.keys():\n",
    "            edges = pd.DataFrame(sub_dict[\"supervision_edges\"]).rename(columns={0:edge_type[0],1:edge_type[2]})\n",
    "            edge_labels_df = pd.concat([edges,pd.DataFrame(sub_dict[\"supervision_labels\"])],axis=1).rename(columns={0:\"label\"})\n",
    "\n",
    "            msg_passing_edges_df = pd.DataFrame(sub_dict[\"message_passing_edges\"]).rename(columns={0:edge_type[0],1:edge_type[2]})\n",
    "\n",
    "            edges_df[edge_type] = {\"supervision_edges\":edge_labels_df,\"message_passing_edges\":msg_passing_edges_df}\n",
    "    \n",
    "    return edges_df\n",
    "\n",
    "def get_edge_df(data,node_map):\n",
    "    inverse_map_dict = inverse_map_heterodata(data,node_map)\n",
    "    df = edge_map_to_df(inverse_map_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_tensor_index_df(node_csv,node_map,node_info)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proporción de samples negativas y positivas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas enfermedades aparecen en supervisión en total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dataset = inverse_map_heterodata(train_data,node_map)\n",
    "df_dataset = edge_map_to_df(mapped_dataset)\n",
    "\n",
    "supervision_edges = df_dataset[(\"gene_protein\",\"gda\",\"disease\")][\"supervision_edges\"]\n",
    "msg_edges = df_dataset[(\"gene_protein\",\"gda\",\"disease\")][\"message_passing_edges\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas enfermedades aparecen en supervisión en total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuantas enf aparecen en supervisión\n",
    "len(supervision_edges.disease.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas enfermedades aparecen en supervisión con samples positivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(supervision_edges[supervision_edges.label == 1].disease.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas enfermedades aparecen en supervisión con samples negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(supervision_edges[supervision_edges.label == 0].disease.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frecuencia de sampleo positiva y negativa vs grado gda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico que son los mismos enlaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_edges = inverse_map_heterodata(val_data,node_map)\n",
    "train_edges = inverse_map_heterodata(train_data,node_map)\n",
    "\n",
    "edge_list = validation_edges[(\"gene_protein\",\"gda\",\"disease\")][\"message_passing_edges\"]\n",
    "gene_to_disease = [(b,a) for (a,b) in edge_list]\n",
    "disease_to_gene = validation_edges[(\"disease\",\"gda\",\"gene_protein\")][\"message_passing_edges\"]\n",
    "\n",
    "len(set(gene_to_disease)&set(disease_to_gene)) == len(gene_to_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(supervision_edges[supervision_edges.label == 1].disease.value_counts(),width=800, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(supervision_edges[supervision_edges.label == 0].disease.value_counts(),width=800, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_negativa_disease = supervision_edges[supervision_edges.label==0].disease.value_counts()\n",
    "frec_positiva_disease = supervision_edges[supervision_edges.label == 1].disease.value_counts()\n",
    "\n",
    "frec_negativa_disease_df = pd.merge(frec_negativa_disease, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_negativa\"})\n",
    "\n",
    "frec_positiva_disease_df = pd.merge(frec_positiva_disease, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_positiva\"})\n",
    "frec_positiva_disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(frec_negativa_disease_df,\"frec_negativa\",\"degree_gda\",title=\"Frecuencia de sampleo negativa - Disease\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(frec_positiva_disease_df,\"frec_positiva\",\"degree_gda\", title=\"Frecuencia de sampleo positiva - Disease\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_negativa_gene = supervision_edges[supervision_edges.label==0].gene_protein.value_counts()\n",
    "frec_positiva_gene = supervision_edges[supervision_edges.label == 1].gene_protein.value_counts()\n",
    "\n",
    "frec_negativa_gene_df = pd.merge(frec_negativa_gene, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"gene_protein\":\"frec_negativa\"})\n",
    "\n",
    "frec_positiva_gene_df = pd.merge(frec_positiva_gene, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"gene_protein\":\"frec_positiva\"})\n",
    "frec_positiva_gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(frec_negativa_gene_df,\"frec_negativa\",\"degree_gda\",title=\"Frecuencia de sampleo negativa - Genes\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(frec_positiva_gene_df,\"frec_positiva\",\"degree_gda\",title=\"Frecuencia de sampleo positiva - Genes\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para un dado nodo, como quedan los splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info.sort_values(by=\"degree_gda\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_index = 18773\n",
    "dataset = val_data\n",
    "\n",
    "mapped_dataset = inverse_map_heterodata(dataset,node_map)\n",
    "df_dataset = edge_map_to_df(mapped_dataset)\n",
    "\n",
    "supervision_edges = df_dataset[(\"gene_protein\",\"gda\",\"disease\")][\"supervision_edges\"]\n",
    "node_supervision_edges = supervision_edges[supervision_edges.disease == node_index]\n",
    "\n",
    "msg_edges = df_dataset[(\"gene_protein\",\"gda\",\"disease\")][\"message_passing_edges\"]\n",
    "node_msg_edges = msg_edges[msg_edges.disease == node_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_msg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_supervision_edges.label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the horror"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo otros métodos de sampleo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está la opción de no samplear de una para los 3 splits y hacer el sampleo para cada pasada de entrenamiento. Vamos a ver como queda eso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling, structured_negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# Cargo el heterodata completo\n",
    "path = data_folder + \"split_dataset/seed_0/full_dataset.pt\"\n",
    "full_dataset = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_types(edge_types):\n",
    "    newlist = []\n",
    "    for edge in edge_types:\n",
    "        rev = tuple(reversed(edge))\n",
    "        if rev != edge:\n",
    "            if edge not in newlist:\n",
    "                newlist.append(rev)\n",
    "        else:\n",
    "            newlist.append(rev)\n",
    "\n",
    "    reversed_newlist = [tuple(reversed(edge)) for edge in newlist]\n",
    "\n",
    "    return newlist, reversed_newlist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago un split ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types, rev_edge_types = get_reverse_types(full_dataset.edge_types)\n",
    "p_val = 0.1\n",
    "p_test = 0.1\n",
    "p_train = round(1 - p_val - p_test, 1)\n",
    "disjoint_ratio = 0.2\n",
    "\n",
    "split_transform = T.RandomLinkSplit(num_val=p_val, num_test=p_test, is_undirected=True, add_negative_train_samples=False,\n",
    "                                    disjoint_train_ratio=disjoint_ratio, edge_types=edge_types, rev_edge_types=rev_edge_types)\n",
    "transform_dataset = T.Compose(\n",
    "    [split_transform, T.ToSparseTensor(remove_edge_index=False)])\n",
    "\n",
    "train_data, val_data, test_data = transform_dataset(full_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative sampling estandar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora val y test tienen samples positivas y negativas, pero **train solo tiene samples positivas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling, structured_negative_sampling\n",
    "\n",
    "dataset = copy.copy(train_data)\n",
    "edge_index = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_index\"]\n",
    "edge_label = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label\"]\n",
    "edge_label_index = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"]\n",
    "\n",
    "num_samples = len(edge_label)\n",
    "num_nodes = (dataset[\"gene_protein\"][\"num_nodes\"],dataset[\"disease\"][\"num_nodes\"])\n",
    "negative_sample = negative_sampling(edge_index,num_nodes=num_nodes,num_neg_samples=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_index = torch.concat((edge_label_index,negative_sample),dim=1)\n",
    "new_label = torch.concat((edge_label,torch.zeros_like(edge_label)))\n",
    "\n",
    "dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"] = new_label_index\n",
    "dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label\"] = new_label\n",
    "\n",
    "new_df = get_edge_df(dataset,node_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervision_edges = new_df[\"gene_protein\",\"gda\",\"disease\"][\"supervision_edges\"]\n",
    "frec_negativa = supervision_edges[supervision_edges.label==0].disease.value_counts()\n",
    "frec_positiva = supervision_edges[supervision_edges.label == 1].disease.value_counts()\n",
    "\n",
    "frec_negativa_df = pd.merge(frec_negativa, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_negativa\"})\n",
    "frec_positiva_df = pd.merge(frec_positiva, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_positiva\"})\n",
    "\n",
    "\n",
    "fig1 = px.scatter(frec_negativa_df,\"frec_negativa\",\"degree_gda\")\n",
    "fig2 = px.scatter(frec_positiva_df,\"frec_positiva\",\"degree_gda\")\n",
    "\n",
    "fig1.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured negative sampling \n",
    "Genera un enlace negativo por cada enlace positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = copy.copy(train_data)\n",
    "edge_index = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_index\"]\n",
    "edge_label = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label\"]\n",
    "edge_label_index = dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"]\n",
    "\n",
    "num_samples = len(edge_label)\n",
    "num_nodes = (dataset[\"gene_protein\"][\"num_nodes\"],dataset[\"disease\"][\"num_nodes\"])\n",
    "negative_sample = structured_negative_sampling(edge_label_index,num_nodes[1],contains_neg_self_loops=False)\n",
    "negative_sample_index = torch.stack((negative_sample[0],negative_sample[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_index = torch.concat((edge_label_index,negative_sample_index),dim=1)\n",
    "new_label = torch.concat((edge_label,torch.zeros_like(edge_label)))\n",
    "\n",
    "dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"] = new_label_index\n",
    "dataset[\"gene_protein\",\"gda\",\"disease\"][\"edge_label\"] = new_label\n",
    "\n",
    "new_df = get_edge_df(dataset,node_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervision_edges = new_df[\"gene_protein\",\"gda\",\"disease\"][\"supervision_edges\"]\n",
    "frec_negativa = supervision_edges[supervision_edges.label==0].disease.value_counts()\n",
    "frec_positiva = supervision_edges[supervision_edges.label == 1].disease.value_counts()\n",
    "\n",
    "frec_negativa_df = pd.merge(frec_negativa, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_negativa\"})\n",
    "frec_positiva_df = pd.merge(frec_positiva, node_info[[\"degree_gda\",\"node_index\"]].set_index(\"node_index\"),right_index=True,left_index=True,how=\"left\").rename(columns={\"disease\":\"frec_positiva\"})\n",
    "\n",
    "fig1 = px.scatter(frec_negativa_df,\"frec_negativa\",\"degree_gda\")\n",
    "fig2 = px.scatter(frec_positiva_df,\"frec_positiva\",\"degree_gda\")\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "es medio lo mismo no. Igual creo que estaría bueno usar este para que no haya leaks, osea, los positivos de train no van a ser los positivos de val, perturbando los de train evito que se solapen? ?? nose!? Tendría que ver esto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo otras formas de samplear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución deg 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampler:\n",
    "    def __init__(self,full_dataset,edge_type,src_degrees,dst_degrees) -> None:\n",
    "        src_type, _ , dst_type = edge_type\n",
    "        self.num_nodes = (dataset[src_type][\"num_nodes\"],dataset[dst_type][\"num_nodes\"])\n",
    "\n",
    "        full_positive_index = full_dataset.edge_index_dict[edge_type]\n",
    "        self.full_positive_hash = self.index_to_hash(full_positive_index)\n",
    "\n",
    "        self.weights = [src_degrees,dst_degrees]\n",
    "    \n",
    "    def index_to_hash(self,edge_index):\n",
    "        size = self.num_nodes\n",
    "        row, col = edge_index\n",
    "        hashed_edges = (row * size[1]).add_(col)\n",
    "        return hashed_edges\n",
    "\n",
    "    def hash_to_index(self,hashed_edges):\n",
    "        size = self.num_nodes\n",
    "        row = hashed_edges.div(size[1], rounding_mode='floor')\n",
    "        col = hashed_edges % size[1]\n",
    "        return torch.stack([row, col], dim=0)\n",
    "    \n",
    "    def sample_negatives(self,num_samples,src_or_dst):\n",
    "        \"\"\"num_samples: number of samples generated, output will have shape [num_samples]. \n",
    "        src_or_dst: use src or dst weights to generate sample. 0:src weights, 1:dst weights\n",
    "        \"\"\"\n",
    "        probs = torch.tensor(self.weights[src_or_dst]**0.75)\n",
    "        neg_samples = probs.multinomial(num_samples, replacement=True)\n",
    "        return neg_samples\n",
    "    \n",
    "    def generate_negative_edge_index(self,positive_edge_index,method):\n",
    "        if method == \"corrupt_both\":\n",
    "            num_samples = positive_edge_index.shape[1]\n",
    "            new_src_index = self.sample_negatives(num_samples,0)\n",
    "            new_dst_index = self.sample_negatives(num_samples,1)\n",
    "            negative_edge_index = torch.stack([new_src_index,new_dst_index])\n",
    "            return negative_edge_index\n",
    "        elif method == \"fix_src\":\n",
    "            src_index, _ = positive_edge_index\n",
    "            new_dst_index = self.sample_negatives(src_index.numel(),1)\n",
    "            negative_edge_index = torch.stack([src_index,new_dst_index])\n",
    "            return negative_edge_index\n",
    "        elif method == \"fix_dst\":\n",
    "            _, dst_index = positive_edge_index\n",
    "            new_src_index = self.sample_negatives(dst_index.numel(),0)\n",
    "            negative_edge_index = torch.stack([new_src_index,dst_index])\n",
    "            return negative_edge_index            \n",
    "    \n",
    "    def test_false_negatives(self,negative_edge_index,positive_edge_index):\n",
    "        full_hash = self.full_positive_hash\n",
    "        negative_hash = self.index_to_hash(negative_edge_index)\n",
    "        positive_hash = self.index_to_hash(positive_edge_index)\n",
    "\n",
    "        false_negatives_mask = torch.isin(negative_hash,full_hash)\n",
    "        new_negative_hash = negative_hash[~false_negatives_mask]\n",
    "        retry_positive_hash = positive_hash[false_negatives_mask]\n",
    "\n",
    "        return new_negative_hash, retry_positive_hash\n",
    "    \n",
    "    def get_negative_sample(self,positive_edge_index,method):\n",
    "        \"\"\"positive_edge_index: edge_index with positive edges, this method will use positive_edge_index as a starting point to generate a negative index\n",
    "        with the same shape as positive_edge_index.\n",
    "        \n",
    "        method: \n",
    "        corrupt_both: sample both src and dst nodes with probability deg**0.75\n",
    "        fix_src: keep original src nodes and sample dst nodes with probability deg**0.75\n",
    "        fix_dst: like fix_src but keep original dst nodes\"\"\"\n",
    "        true_negatives = []\n",
    "        retry_positive_hash = torch.tensor([0]) #placeholder\n",
    "        temp_positive_edge_index = copy.copy(positive_edge_index)\n",
    "\n",
    "        while retry_positive_hash.numel() > 0:\n",
    "            negative_edge_index = self.generate_negative_edge_index(temp_positive_edge_index,method)\n",
    "            true_neg_hash, retry_positive_hash = self.test_false_negatives(negative_edge_index,temp_positive_edge_index)\n",
    "\n",
    "            true_negatives.append(true_neg_hash)\n",
    "            temp_positive_edge_index = self.hash_to_index(retry_positive_hash)\n",
    "\n",
    "\n",
    "        negative_edge_hash = torch.concat(true_negatives)\n",
    "        negative_edge_index = self.hash_to_index(negative_edge_hash)\n",
    "\n",
    "        return negative_edge_index\n",
    "    \n",
    "    def get_labeled_tensors(self,positive_edge_index,method):\n",
    "        sample = self.get_negative_sample(positive_edge_index,method)\n",
    "        edge_label_index = torch.concat([positive_edge_index,sample],dim=1)\n",
    "        edge_label = torch.concat([torch.ones(positive_edge_index.shape[1]), torch.zeros(positive_edge_index.shape[1])])\n",
    "        return edge_label_index, edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_folder +\"split_dataset/seed_0/full_dataset.pt\"\n",
    "full_dataset = torch.load(path)\n",
    "\n",
    "src_degrees = df[df.node_type == \"gene_protein\"][\"degree_gda\"].values\n",
    "dst_degrees = df[df.node_type == \"disease\"][\"degree_gda\"].values\n",
    "edge_type = (\"gene_protein\",\"gda\",\"disease\")\n",
    "positive_edge_index = train_data.edge_label_index_dict[edge_type]\n",
    "\n",
    "negative_sampler = NegativeSampler(full_dataset,(\"gene_protein\",\"gda\",\"disease\"),src_degrees,dst_degrees)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifico frecuencia de falsos negativos (pasa si se solapan dos hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sample = negative_sampler.get_negative_sample(positive_edge_index,\"corrupt_both\")\n",
    "true_neg,false_neg = negative_sampler.test_false_negatives(sample,positive_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries = 400\n",
    "total = []\n",
    "for _ in range(tries):\n",
    "    sample = negative_sampler.get_negative_sample(positive_edge_index,\"corrupt_both\")\n",
    "    true_neg,false_neg = negative_sampler.test_false_negatives(sample,positive_edge_index)\n",
    "    total.append(false_neg.numel())\n",
    "\n",
    "plt.hist(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neg_frequency(sample,node_type,df=df):\n",
    "    i = 0 if node_type == \"gene_protein\" else 1\n",
    "    unique, counts = np.unique(sample[i].numpy(),return_counts=True)\n",
    "    frec_negativa_df = pd.DataFrame([unique,counts]).T.rename(columns={0:\"tensor_index\",1:\"frecuencia_negativa\"})\n",
    "    frec_negativa_df = frec_negativa_df.merge(df.loc[df.node_type == node_type,[\"tensor_index\",\"degree_gda\"]],left_on=\"tensor_index\",right_on=\"tensor_index\",how=\"left\")\n",
    "    frec_negativa_df.sort_values(by=\"frecuencia_negativa\",ascending=False)\n",
    "\n",
    "    fig = px.scatter(frec_negativa_df,\"frecuencia_negativa\",\"degree_gda\",title=f\"Frecuencia de sampleo negativa - {node_type}\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = negative_sampler.get_negative_sample(positive_edge_index,\"corrupt_both\")\n",
    "\n",
    "plot_neg_frequency(sample,\"gene_protein\")\n",
    "plot_neg_frequency(sample,\"disease\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificar que no genere leaks (mismo negativo en diferentes splits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad de generar leaks es muy baja, no creo que valga la pena resamplear por esto durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_data[edge_type][\"edge_label\"]\n",
    "val_labeled_edges = val_data[edge_type][\"edge_label_index\"]\n",
    "\n",
    "index = torch.nonzero(val_labels == 0).flatten()\n",
    "val_negative_edges = val_labeled_edges[:,index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_leaks(negative_train_index, negative_val_index):\n",
    "    train_hash = negative_sampler.index_to_hash(negative_train_index)\n",
    "    val_hash = negative_sampler.index_to_hash(negative_val_index)\n",
    "\n",
    "    leaked_negatives_mask = torch.isin(train_hash,val_hash)\n",
    "\n",
    "    return leaked_negatives_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries = 1000\n",
    "total = []\n",
    "for _ in range(tries):\n",
    "    sample = negative_sampler.get_negative_sample(positive_edge_index,\"corrupt_both\")\n",
    "    leaks = test_leaks(sample,val_negative_edges)\n",
    "    total.append(leaks.sum())\n",
    "\n",
    "plt.hist(np.array(total),density=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generar las muestras negativas para val y test? xq esa distribución tmb va a ser rara"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neg_frequency(val_negative_edges,\"gene_protein\")\n",
    "plot_neg_frequency(val_negative_edges,\"disease\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poner el negative index generado y las labels en el heterodata correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_data[edge_type][\"edge_label\"]\n",
    "val_labeled_edges = val_data[edge_type][\"edge_label_index\"]\n",
    "\n",
    "index = torch.nonzero(val_labels == 1).flatten()\n",
    "val_positive_edges = val_labeled_edges[:,index]\n",
    "\n",
    "new_val_label_index, new_val_label = negative_sampler.get_labeled_tensors(val_positive_edges,\"corrupt_both\") #ok it works\n",
    "\n",
    "index = torch.nonzero(new_val_label == 0).flatten()\n",
    "sample = new_val_label_index[:,index]\n",
    "plot_neg_frequency(sample,\"disease\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiero ver que pasa con el disjoint ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo que la idea seria ver cuantos enlaces quedan para supervisión vs propagación para los dif nodos. Osea las distribuciones según grado de N_sup y N_prop. Idem los números crudos totales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_type = (\"gene_protein\",\"gda\",\"disease\")\n",
    "datasets, node_map = training_utils.load_data(data_folder+\"split_dataset/seed_4/\")\n",
    "train_data,val_data = datasets\n",
    "\n",
    "train_labels = train_data[edge_type][\"edge_label\"]\n",
    "train_labeled_edges = train_data[edge_type][\"edge_label_index\"]\n",
    "\n",
    "index = torch.nonzero(train_labels == 1).flatten()\n",
    "train_positive_edges = train_labeled_edges[:,index]\n",
    "\n",
    "new_train_label_index, new_train_label = negative_sampler.get_labeled_tensors(train_positive_edges,\"corrupt_both\")\n",
    "\n",
    "train_data[edge_type][\"edge_label\"] = new_train_label\n",
    "train_data[edge_type][\"edge_label_index\"] = new_train_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dataset = inverse_map_heterodata(val_data,node_map)\n",
    "df_dataset = edge_map_to_df(mapped_dataset)\n",
    "supervision_edges = df_dataset[\"gene_protein\",\"gda\",\"disease\"][\"supervision_edges\"]\n",
    "propagation_edges = df_dataset[\"gene_protein\",\"gda\",\"disease\"][\"message_passing_edges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"degree_gda\",ascending=False)[3500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_index = 23069\n",
    "display(supervision_edges[supervision_edges.disease == node_index], len(supervision_edges[supervision_edges.disease == node_index]))\n",
    "display(propagation_edges[propagation_edges.disease == node_index],len(propagation_edges[propagation_edges.disease == node_index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
