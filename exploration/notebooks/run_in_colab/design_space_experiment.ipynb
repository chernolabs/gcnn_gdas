{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Colab\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on Colab')\n",
    "  running_on_colab = True\n",
    "else:\n",
    "  print('Not running on Colab')\n",
    "  running_on_colab = False\n",
    "\n",
    "if running_on_colab:\n",
    "    print(torch.__version__)\n",
    "    !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "    !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
    "    !pip install pyarrow\n",
    "    !pip install fastparquet\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    filepath = '/content/drive/MyDrive/GCNN/'\n",
    "    data_folder = filepath+\"graph_data/\"\n",
    "    experiments_folder = filepath+\"experiments/merged_types_experiments/\"\n",
    "\n",
    "    import sys\n",
    "    sys.path.append(filepath + \"run_in_colab\")\n",
    "\n",
    "else:\n",
    "    data_folder = \"../../../data/processed/graph_data_nohubs/merged_types/\"\n",
    "    experiments_folder = \"../../../data/experiments/design_space_merged_experiment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base_model, training_utils\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_folder + \"split_dataset/\"\n",
    "original_train_data, original_val_data = training_utils.load_data(path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(params, train_set, val_set):\n",
    "\n",
    "    # Initialize node features\n",
    "    train_set = training_utils.initialize_features(\n",
    "        train_set, params[\"feature_type\"], params[\"feature_dim\"])\n",
    "    val_set = training_utils.initialize_features(\n",
    "        val_set, params[\"feature_type\"], params[\"feature_dim\"])\n",
    "    train_set.to(device)\n",
    "    val_set.to(device)\n",
    "\n",
    "    # Initialize model\n",
    "    model = base_model.base_model(\n",
    "        params, train_set.metadata(), params[\"supervision_types\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=params['lr'], weight_decay=params[\"weight_decay\"])\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "\n",
    "    metric = roc_auc_score\n",
    "    epochs = params[\"epochs\"]\n",
    "\n",
    "    early_stopper = training_utils.EarlyStopper(\n",
    "        params[\"patience\"], params[\"delta\"])\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = training_utils.train(model, optimizer, train_set)\n",
    "        val_loss = training_utils.get_val_loss(model, val_set)\n",
    "\n",
    "        train_score = training_utils.test(model, train_set, metric)\n",
    "        val_score = training_utils.test(model, val_set, metric)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_scores.append(train_score)\n",
    "\n",
    "        val_scores.append(val_score)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    val_auc = training_utils.test(model, val_set, roc_auc_score)\n",
    "    curve_data = [train_losses, val_losses, train_scores, val_scores]\n",
    "\n",
    "    return val_auc, model, curve_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a grid of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "def perform_hyperparameter_search(param_grid, train_set, val_set):\n",
    "  \n",
    "  default = {\n",
    "      \"hidden_channels\":[32],\n",
    "      \"conv_type\":[\"SAGEConv\"],\n",
    "      \"batch_norm\": [True],\n",
    "      \"dropout\":[0.1],\n",
    "      \"micro_aggregation\":[\"mean\"],\n",
    "      \"macro_aggregation\":[\"mean\"],\n",
    "      \"layer_connectivity\":[None],\n",
    "      \"L2_norm\":[False],\n",
    "      \"pre_process_layers\":[0],\n",
    "      \"msg_passing_layers\":[2],\n",
    "      \"post_process_layers\":[0],\n",
    "      \"normalize_output\":[False],\n",
    "      \"jumping_knowledge\":[False],\n",
    "\n",
    "      \"feature_dim\":[10],\n",
    "      \"feature_type\":[\"random\"],\n",
    "      \"supervision_types\":[[('gene_protein', 'gda', 'disease')]],\n",
    "\n",
    "      'weight_decay': [1e-3],\n",
    "      'lr': [0.001],\n",
    "      'epochs':[400],\n",
    "      \"patience\":[10],\n",
    "      \"delta\":[0.1]\n",
    "  }\n",
    "\n",
    "  for arg in default:\n",
    "    if arg not in param_grid:\n",
    "      param_grid[arg] = default[arg]\n",
    "\n",
    "  grid = ParameterGrid(param_grid)\n",
    "\n",
    "  auc_results = []\n",
    "  models = []\n",
    "\n",
    "  for eid,params in enumerate(grid):\n",
    "    # Launch a training experiment using the current set of parameters\n",
    "    val_auc,current_model,curve_data = run_experiment(\n",
    "                   params,\n",
    "                   train_set,\n",
    "                   val_set)\n",
    "    \n",
    "    params[\"auc\"] = val_auc\n",
    "    params[\"curve_data\"] = curve_data\n",
    "\n",
    "    auc_results.append(params)\n",
    "    models.append(current_model)\n",
    "\n",
    "    print(f\"Validation AUC: {round(val_auc,2)}. Iteration: {eid+1} of {grid.__len__()}\")\n",
    "\n",
    "  return auc_results, models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run multiple grids of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_grids(grid_list,train_data,val_data):\n",
    "    all_results = []\n",
    "    all_models = []\n",
    "\n",
    "    date = datetime.datetime.now()\n",
    "    fdate = date.strftime(\"%d_%m_%y__%H_%M_%S\")\n",
    "    fname = experiments_folder+\"experiment_\"+fdate+\".parquet\"\n",
    "\n",
    "    for i,grid in enumerate(grid_list):\n",
    "        print(f\"Experiment grid {i+1} of {len(grid_list)}\")\n",
    "        experiment_results, models = perform_hyperparameter_search(grid, train_data,val_data)\n",
    "        results_df = pd.DataFrame(experiment_results)\n",
    "\n",
    "        all_results.append(results_df)\n",
    "        all_models.append(models)\n",
    "\n",
    "        current_results = pd.concat(all_results).reset_index(drop=True)\n",
    "        current_models =  list(itertools.chain(*all_models))\n",
    "\n",
    "        print(f\"Saving results from grid {i+1} ...\")\n",
    "        current_results.to_parquet(fname)\n",
    "        for i, model in enumerate(current_models):\n",
    "            model_name = f\"experiment_{i}\"\n",
    "            training_utils.save_model(model,experiments_folder,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_grid = {\n",
    "    \"hidden_channels\":[32],\n",
    "    \"conv_type\":[\"GATConv\"],\n",
    "    \"batch_norm\": [True],\n",
    "    \"dropout\":[0.1],\n",
    "    \"micro_aggregation\":[\"sum\"],\n",
    "    \"macro_aggregation\":[\"sum\"],\n",
    "    \"layer_connectivity\":[None],\n",
    "    \"L2_norm\":[True],\n",
    "    \"pre_process_layers\":[0],\n",
    "    \"msg_passing_layers\":[2],\n",
    "    \"post_process_layers\":[1],\n",
    "    \"normalize_output\":[False],\n",
    "    \"jumping_knowledge\":[False],\n",
    "    \"heads\":[2],\n",
    "\n",
    "    \"feature_dim\":[10],\n",
    "    \"feature_type\":[\"ones\"],\n",
    "    \"supervision_types\":[[('gene_protein', 'gda', 'disease')]],\n",
    "\n",
    "    'weight_decay': [1e-3],\n",
    "    'lr': [0.001],\n",
    "    'epochs':[400],\n",
    "    \"patience\":[10],\n",
    "    \"delta\":[0.1],\n",
    "\n",
    "    \"experiment_name\" : [\"default_experiment\"]\n",
    "}\n",
    "\n",
    "grid_list = []\n",
    "\n",
    "grid_1 = {\"hidden_channels\":[32,64,128],\"micro_aggregation\":[\"sum\",\"mean\",\"max\"],\"macro_aggregation\":[\"sum\",\"mean\",\"max\"],\"feature_dim\":[10,50,100],\"feature_type\":[\"ones\",\"random\"]}\n",
    "grid_list.append(default_grid|grid_1)\n",
    "\n",
    "grid_2 = {\"hidden_channels\":[32],\"conv_type\":[\"SAGEConv\",\"GATConv\"],\"micro_aggregation\":[\"sum\",\"mean\",\"max\"],\"macro_aggregation\":[\"sum\",\"mean\",\"max\"],\"feature_type\":[\"ones\",\"random\"]}\n",
    "grid_list.append(default_grid|grid_2)\n",
    "\n",
    "grid_3 = {\"layer_connectivity\":[None,\"skipsum\"],\"msg_passing_layers\":[2,3,4,5],\"jumping_knowledge\":[False,True]}\n",
    "grid_list.append(default_grid|grid_3)\n",
    "\n",
    "grid_4 = {\"L2_norm\":[True,False],\"conv_type\":[\"SAGEConv\",\"GATConv\"],\"normalize_output\":[True,False]}\n",
    "grid_list.append(default_grid|grid_4)\n",
    "\n",
    "grid_5 = {\"pre_process_layers\":[0,1,2],\"post_process_layers\":[0,1,2],\"msg_passing_layers\":[0,1,2],\"feature_type\":[\"ones\",\"random\"]}\n",
    "grid_list.append(default_grid|grid_5)\n",
    "\n",
    "grid_6 = {\"batch_norm\":[True,False],\"dropout\":[0,0.1,0.01]}\n",
    "grid_list.append(default_grid|grid_6)\n",
    "\n",
    "num_experiments = sum([np.prod([len(val) for val in grid.values()]) for grid in grid_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results,model = perform_hyperparameter_search(default_grid,original_train_data,original_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 159 experiments ...\n",
      "Experiment grid 1 of 1\n",
      "Validation AUC: 0.86. Iteration: 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running {num_experiments} experiments ...\")\n",
    "run_multiple_grids(grid_list,original_train_data,original_val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
