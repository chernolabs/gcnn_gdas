{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Colab\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on Colab')\n",
    "  running_on_colab = True\n",
    "else:\n",
    "  print('Not running on Colab')\n",
    "  running_on_colab = False\n",
    "\n",
    "if running_on_colab:\n",
    "    print(torch.__version__)\n",
    "    !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "    !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    filepath = '/content/drive/MyDrive/GCNN/'\n",
    "    data_folder = filepath+\"graph_data/split_dataset/\"\n",
    "    feature_folder = data_folder\n",
    "    experiments_folder = filepath+\"experiments/hyperparameter_tuning/\"\n",
    "    import sys\n",
    "    sys.path.append(filepath + \"run_in_colab\")\n",
    "\n",
    "else:\n",
    "    data_folder = \"../../../data/processed/graph_data_nohubs/merged_types/split_dataset/\"\n",
    "    experiments_folder = \"../../../reports/model_selection/hyperparameter_tuning/\"\n",
    "    feature_folder = \"../../../data/processed/feature_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage_lsa, colab_utils\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [4,5,6,7,8]\n",
    "data = []\n",
    "for seed in seeds:\n",
    "    datasets, node_map = colab_utils.load_data(data_folder+f\"seed_{seed}/\")\n",
    "    data.append(datasets)\n",
    "\n",
    "full_set = torch.load(data_folder+f\"seed_{seeds[-1]}/full_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(params, train_set, val_set,negative_sampler,feature_folder=feature_folder):\n",
    "    # Initialize node features\n",
    "    train_set = colab_utils.initialize_features(train_set, \"lsa_scaled\", 32, feature_folder)\n",
    "    val_set = colab_utils.initialize_features(val_set, \"lsa_scaled\", 32, feature_folder)\n",
    "\n",
    "    train_set.to(device)\n",
    "    val_set.to(device)\n",
    "\n",
    "    # Initialize model\n",
    "    model = sage_lsa.Model(train_set.metadata(),[(\"gene_protein\",\"gda\",\"disease\")],params[\"first_layer_dropout\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=params[\"lr\"], weight_decay=params[\"weight_decay\"]\n",
    "    )\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # train_scores = []\n",
    "    # val_scores = []\n",
    "\n",
    "    epochs = 400\n",
    "    patience = 10\n",
    "    delta = 0.1\n",
    "\n",
    "    early_stopper = colab_utils.EarlyStopper(patience, delta)\n",
    "    train_label_index = train_set[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #Resample negative supervision links every epoch\n",
    "        new_train_label_index, new_train_label = negative_sampler.get_labeled_tensors(train_label_index.cpu(),\"corrupt_both\")\n",
    "        train_set[\"gene_protein\",\"gda\",\"disease\"][\"edge_label_index\"] = new_train_label_index.to(device)\n",
    "        train_set[\"gene_protein\",\"gda\",\"disease\"][\"edge_label\"] = new_train_label.to(device)\n",
    "\n",
    "        train_loss = colab_utils.train(model, optimizer, train_set)\n",
    "        val_loss = colab_utils.get_val_loss(model, val_set)\n",
    "\n",
    "        # train_score = colab_utils.test(model, train_set)\n",
    "        # val_score = colab_utils.test(model, val_set)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        # train_scores.append(train_score)\n",
    "\n",
    "        # val_scores.append(val_score)\n",
    "        # val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    val_auc = colab_utils.test(model, val_set)\n",
    "    # curve_data = [train_losses, val_losses, train_scores, val_scores]\n",
    "    final_val_CE = val_losses[-1]\n",
    "    final_train_CE = train_losses[-1]\n",
    "\n",
    "    return val_auc, final_val_CE, final_train_CE\n",
    "\n",
    "def run_multiple_seeds(datasets,experiment_params,negative_sampler):\n",
    "    experiment_auc = []\n",
    "    experiment_val_CE = []\n",
    "    experiment_train_CE = []\n",
    "    # curves = []\n",
    "    for seed_dataset in datasets:\n",
    "        train_data, val_data = seed_dataset\n",
    "        seed_auc, seed_val_CE, seed_train_CE = run_experiment(experiment_params,train_data,val_data,negative_sampler)\n",
    "        experiment_auc.append(seed_auc)\n",
    "        experiment_val_CE.append(seed_val_CE)\n",
    "        experiment_train_CE.append(seed_train_CE)\n",
    "    \n",
    "    mean_auc = (np.mean(experiment_auc),np.std(experiment_auc))\n",
    "    val_CE = (np.mean(experiment_val_CE),np.std(experiment_val_CE))\n",
    "    train_CE = (np.mean(experiment_train_CE),np.std(experiment_train_CE))\n",
    "    \n",
    "    return [mean_auc, val_CE, train_CE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m negative_sampler \u001b[39m=\u001b[39m colab_utils\u001b[39m.\u001b[39mNegativeSampler(full_set,(\u001b[39m\"\u001b[39m\u001b[39mgene_protein\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgda\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdisease\u001b[39m\u001b[39m\"\u001b[39m),full_set[\u001b[39m\"\u001b[39m\u001b[39mgene_protein\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdegree_gda\u001b[39m\u001b[39m\"\u001b[39m],full_set[\u001b[39m\"\u001b[39m\u001b[39mdisease\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdegree_gda\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m exp_id,params \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(grid):\n\u001b[0;32m---> 15\u001b[0m     mean_auc, val_CE, train_CE \u001b[39m=\u001b[39m run_multiple_seeds(data,params,negative_sampler)\n\u001b[1;32m     16\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mmean_auc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mean_auc[\u001b[39m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m mean_auc[\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mrun_multiple_seeds\u001b[0;34m(datasets, experiment_params, negative_sampler)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m seed_dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m     63\u001b[0m     train_data, val_data \u001b[39m=\u001b[39m seed_dataset\n\u001b[0;32m---> 64\u001b[0m     seed_auc, seed_val_CE, seed_train_CE \u001b[39m=\u001b[39m run_experiment(experiment_params,train_data,val_data,negative_sampler)\n\u001b[1;32m     65\u001b[0m     experiment_auc\u001b[39m.\u001b[39mappend(seed_auc)\n\u001b[1;32m     66\u001b[0m     experiment_val_CE\u001b[39m.\u001b[39mappend(seed_val_CE)\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(params, train_set, val_set, negative_sampler, feature_folder)\u001b[0m\n\u001b[1;32m     31\u001b[0m train_set[\u001b[39m\"\u001b[39m\u001b[39mgene_protein\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgda\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdisease\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39medge_label_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m new_train_label_index\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m train_set[\u001b[39m\"\u001b[39m\u001b[39mgene_protein\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgda\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdisease\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39medge_label\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m new_train_label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m train_loss \u001b[39m=\u001b[39m colab_utils\u001b[39m.\u001b[39;49mtrain(model, optimizer, train_set)\n\u001b[1;32m     35\u001b[0m val_loss \u001b[39m=\u001b[39m colab_utils\u001b[39m.\u001b[39mget_val_loss(model, val_set)\n\u001b[1;32m     37\u001b[0m \u001b[39m# train_score = colab_utils.test(model, train_set)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# val_score = colab_utils.test(model, val_set)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/exploration/notebooks/run_in_colab/colab_utils.py:19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data)\u001b[0m\n\u001b[1;32m     17\u001b[0m edge_label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_label_dict\n\u001b[1;32m     18\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss(predictions, edge_label)\n\u001b[0;32m---> 19\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     20\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    \"first_layer_dropout\": [0.2,0.3,0.5],\n",
    "    \"weight_decay\": [1e-3,1e-2,1e-1],\n",
    "    \"lr\": [1e-3,1e-2,1e-1],\n",
    "}\n",
    "\n",
    "\n",
    "grid = ParameterSampler(grid_params, n_iter=10)\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results = []\n",
    "\n",
    "negative_sampler = colab_utils.NegativeSampler(full_set,(\"gene_protein\",\"gda\",\"disease\"),full_set[\"gene_protein\"][\"degree_gda\"],full_set[\"disease\"][\"degree_gda\"])\n",
    "for exp_id,params in enumerate(grid):\n",
    "    mean_auc, val_CE, train_CE = run_multiple_seeds(data,params,negative_sampler)\n",
    "    params[\"mean_auc\"] = mean_auc[0]\n",
    "    params[\"std\"] = mean_auc[1]\n",
    "    params[\"mean_val_CE\"] = val_CE[0]\n",
    "    params[\"val_CE_std\"] = val_CE[1]\n",
    "    params[\"mean_train_CE\"] = train_CE[0]\n",
    "    params[\"train_CE_std\"] = train_CE[1]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "fdate = date.strftime(\"%d_%m_%y__%H_%M\")\n",
    "\n",
    "results_df.to_csv(experiments_folder + \"random_grid_search\" + fdate + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
