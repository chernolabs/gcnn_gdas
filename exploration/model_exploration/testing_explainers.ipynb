{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.explain import Explainer, CaptumExplainer,ModelConfig,GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../data/processed/graph_data_nohubs/\"\n",
    "models_folder = \"../../data/models/\"\n",
    "experiments_folder = \"../../data/experiments/design_space_experiment/\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from src.models.base_model import base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import SAGEConv,GATConv, to_hetero\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import SAGEConv,GATConv, to_hetero\n",
    "\n",
    "class inner_product_decoder(torch.nn.Module):\n",
    "    def forward(self,x_source,x_target,edge_index,apply_sigmoid=True):\n",
    "        nodes_src = x_source[edge_index[0]]\n",
    "        nodes_trg = x_target[edge_index[1]]\n",
    "        pred = (nodes_src * nodes_trg).sum(dim=-1)\n",
    "\n",
    "        if apply_sigmoid:\n",
    "            pred = torch.sigmoid(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "class base_message_layer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_params,hidden_layer=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Currently SageConv or GATConv, might have to modify this to support other Convs\n",
    "        conv_type = model_params[\"conv_type\"]\n",
    "        self.conv = layer_dict[conv_type]((-1,-1), model_params[\"hidden_channels\"],aggr=model_params[\"micro_aggregation\"],add_self_loops=False)\n",
    "        self.normalize = model_params[\"L2_norm\"]\n",
    "\n",
    "        post_conv_modules = []\n",
    "        if model_params[\"batch_norm\"]:\n",
    "            bn = torch.nn.BatchNorm1d(model_params[\"hidden_channels\"])\n",
    "            post_conv_modules.append(bn)\n",
    "        \n",
    "        if model_params[\"dropout\"] > 0:    \n",
    "            dropout = torch.nn.Dropout(p=model_params[\"dropout\"])\n",
    "            post_conv_modules.append(dropout)\n",
    "        \n",
    "        # No activation on final embedding layer\n",
    "        if hidden_layer:\n",
    "            activation = model_params[\"activation\"]()\n",
    "            post_conv_modules.append(activation)\n",
    "        \n",
    "        self.post_conv = torch.nn.Sequential(*post_conv_modules)\n",
    "\n",
    "    def forward(self, x:dict, edge_index:dict) -> dict:\n",
    "        x = self.conv(x,edge_index)\n",
    "        x = self.post_conv(x)\n",
    "        if self.normalize:\n",
    "            x = torch.nn.functional.normalize(x,2,-1)\n",
    "        return x\n",
    "\n",
    "class multilayer_message_passing(torch.nn.Module):\n",
    "    #TODO: consider input and output dims with skipcat. Currently the two supported convs auto-detect dimensions. Might have to modify this if i add more convs in the future.\n",
    "    def __init__(self,num_layers,model_params,metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.skip = model_params[\"layer_connectivity\"]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            hidden_layer = i != self.num_layers-1\n",
    "            layer = to_hetero(base_message_layer(model_params,hidden_layer),metadata,model_params[\"macro_aggregation\"])\n",
    "            self.add_module(f\"Layer_{i}\",layer)\n",
    "    \n",
    "    def hetero_skipsum(self,x: dict, x_i:dict) -> dict:\n",
    "        x_transformed = {}\n",
    "        for key,x_val in x.items():\n",
    "            x_i_val = x_i[key]\n",
    "            transformed_val = x_val + x_i_val\n",
    "            x_transformed[key] = transformed_val\n",
    "\n",
    "        return x_transformed\n",
    "\n",
    "    def hetero_skipcat(self,x: dict, x_i:dict) -> dict:\n",
    "        x_transformed = {}\n",
    "        for key,x_val in x.items():\n",
    "            x_i_val = x_i[key]\n",
    "            transformed_val = torch.cat([x_val,x_i_val],dim=-1)\n",
    "            x_transformed[key] = transformed_val\n",
    "\n",
    "        return x_transformed\n",
    "    \n",
    "    def forward(self, x:dict, edge_index:dict) -> dict:\n",
    "        for i, layer in enumerate(self.children()):\n",
    "            x_i = x\n",
    "            x = layer(x,edge_index)\n",
    "            if self.skip == \"skipsum\":\n",
    "                x = self.hetero_skipsum(x,x_i)\n",
    "            elif self.skip == \"skipcat\" and i < self.num_layers -1:\n",
    "                x = self.hetero_skipcat(x,x_i)\n",
    "        \n",
    "        return x \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self,num_layers,in_dim,out_dim,model_params,hidden_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim = out_dim if hidden_dim is None else hidden_dim\n",
    "        \n",
    "        modules = []\n",
    "        if num_layers == 1:\n",
    "            modules.append(torch.nn.Linear(in_dim,out_dim))\n",
    "        else:\n",
    "            for i in range(num_layers):\n",
    "                final_layer = i == num_layers-1\n",
    "                first_layer = i == 0\n",
    "                if first_layer:\n",
    "                    modules.append(torch.nn.Linear(in_dim,hidden_dim))\n",
    "                    modules.append(model_params[\"activation\"]())\n",
    "                elif final_layer:\n",
    "                    modules.append(torch.nn.Linear(hidden_dim,out_dim))\n",
    "                else:\n",
    "                    modules.append(torch.nn.Linear(hidden_dim,hidden_dim))\n",
    "                    modules.append(model_params[\"activation\"]())\n",
    "        \n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class base_encoder(torch.nn.Module):\n",
    "    def __init__(self,model_params,metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.has_pre_mlp = model_params[\"pre_process_layers\"] > 0\n",
    "        self.has_post_mlp = model_params[\"post_process_layers\"] > 0\n",
    "\n",
    "        if self.has_pre_mlp:\n",
    "            self.pre_mlp = to_hetero(MLP(model_params[\"pre_process_layers\"],model_params[\"feature_dim\"],model_params[\"hidden_channels\"],model_params),metadata)\n",
    "        \n",
    "        self.message_passing = multilayer_message_passing(model_params[\"msg_passing_layers\"],model_params,metadata)\n",
    "\n",
    "        if self.has_post_mlp:\n",
    "            self.post_mlp = to_hetero(MLP(model_params[\"post_process_layers\"],model_params[\"hidden_channels\"],model_params[\"hidden_channels\"],model_params),metadata)\n",
    "    \n",
    "    def forward(self,x:dict,edge_index:dict) -> dict :\n",
    "        if self.has_pre_mlp:\n",
    "            x = self.pre_mlp(x)\n",
    "\n",
    "        x = self.message_passing(x,edge_index)\n",
    "        \n",
    "        if self.has_post_mlp:\n",
    "            x = self.post_mlp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class base_model(torch.nn.Module):\n",
    "    def __init__(self, model_params,metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        default_model_params = {\n",
    "            \"hidden_channels\":32,\n",
    "            \"conv_type\":\"SAGEConv\",\n",
    "            \"batch_norm\": True,\n",
    "            \"dropout\":0,\n",
    "            \"activation\":torch.nn.LeakyReLU,\n",
    "            \"micro_aggregation\":\"mean\",\n",
    "            \"macro_aggregation\":\"mean\",\n",
    "            \"layer_connectivity\":None,\n",
    "            \"L2_norm\":False,\n",
    "            \"feature_dim\": 10,\n",
    "            \"pre_process_layers\":0,\n",
    "            \"msg_passing_layers\":2,\n",
    "            \"post_process_layers\":0,\n",
    "        }\n",
    "        \n",
    "        for arg in default_model_params:\n",
    "            if arg not in model_params:\n",
    "                model_params[arg] = default_model_params[arg]\n",
    "        \n",
    "        self.encoder = base_encoder(model_params,metadata)\n",
    "        self.decoder = inner_product_decoder()\n",
    "        self.loss_fn = torch.nn.BCELoss()\n",
    "    \n",
    "    def decode(self,x:dict,edge_label_index:dict,supervision_types):\n",
    "        pred_dict = {}\n",
    "        for edge_type in supervision_types:\n",
    "            edge_index = edge_label_index[edge_type]\n",
    "\n",
    "            src_type = edge_type[0]\n",
    "            trg_type = edge_type[2]\n",
    "\n",
    "            x_src = x[src_type]\n",
    "            x_trg = x[trg_type]\n",
    "\n",
    "            pred = self.decoder(x_src,x_trg,edge_index)\n",
    "\n",
    "            pred_dict[edge_type] = pred\n",
    "        \n",
    "        return pred_dict\n",
    "    \n",
    "    def encode(self,data):\n",
    "        x = data.x_dict\n",
    "        adj_t = data.adj_t_dict\n",
    "\n",
    "        encodings = self.encoder(x,adj_t)\n",
    "        return encodings\n",
    "    \n",
    "    def forward(self,x,adj_t,edge_label_index,supervision_types,return_tensor=False):\n",
    "        # x = data.x_dict\n",
    "        # adj_t = data.adj_t_dict\n",
    "        # edge_label_index = data.edge_label_index_dict\n",
    "\n",
    "        x = self.encoder(x,adj_t)\n",
    "        pred = self.decode(x,edge_label_index,supervision_types)\n",
    "        if return_tensor:\n",
    "            pred = pred[supervision_types[0]]\n",
    "        return pred\n",
    "\n",
    "    def loss(self, prediction_dict, label_dict):\n",
    "        loss = 0\n",
    "        num_types = len(prediction_dict.keys())\n",
    "        for edge_type,pred in prediction_dict.items():\n",
    "            y = label_dict[edge_type]\n",
    "            loss += self.loss_fn(pred, y.type(pred.dtype))\n",
    "        return loss/num_types\n",
    "\n",
    "layer_dict = {\n",
    "    \"GATConv\":GATConv,\n",
    "    \"SAGEConv\":SAGEConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def load_data(folder_path,load_test = False,load_full=False):\n",
    "    if load_test:\n",
    "        names = [\"train\",\"validation\",\"test\"]\n",
    "    else:\n",
    "        names = [\"train\",\"validation\"]\n",
    "    datasets = []\n",
    "    for name in names:\n",
    "        path = folder_path+name+\".pt\"\n",
    "        datasets.append(torch.load(path))\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "def initialize_features(data,feature,dim,inplace=False):\n",
    "    if inplace:\n",
    "        data_object = data\n",
    "    else:\n",
    "        data_object = copy.copy(data)\n",
    "    for nodetype, store in data_object.node_items():\n",
    "        if feature == \"random\":\n",
    "            data_object[nodetype].x = torch.rand(store[\"num_nodes\"],dim)\n",
    "        if feature == \"ones\":\n",
    "            data_object[nodetype].x = torch.ones(store[\"num_nodes\"],dim)\n",
    "    return data_object\n",
    "\n",
    "def load_model(state_dict,params,metadata):\n",
    "    model = base_model(params,metadata,supervision_types=[('gene_protein', 'gda', 'disease')])\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "def load_experiment(eid:int,date:str,metadata:tuple) -> tuple:\n",
    "    \"\"\"Returns tuple (model,params).\n",
    "    date format: d_m_y\"\"\"\n",
    "    df_path = f\"{experiments_folder}experiment_{date}.parquet\"\n",
    "    weights_path = f\"{experiments_folder}experiment_{eid}_{date}__.pth\"\n",
    "\n",
    "    df = pd.read_parquet(df_path)\n",
    "    #TODO: this is only temporal, remove after fix\n",
    "    df[\"conv_type\"] = df.conv_type.apply(lambda x: x.split(\".\")[-1].rstrip(\"\\'>\"))\n",
    "    df[\"activation\"] = torch.nn.LeakyReLU\n",
    "    params = df.loc[eid].to_dict()\n",
    "    weights = torch.load(weights_path,map_location=torch.device(device))\n",
    "\n",
    "    model = base_model(params,metadata)\n",
    "    model.load_state_dict(weights)\n",
    "\n",
    "    return model,params\n",
    "\n",
    "def load_node_csv(path, index_col,type_col, **kwargs):\n",
    "    \"\"\"Returns node dataframe and a dict of mappings for each node type. \n",
    "    Each mapping maps from original df index to \"heterodata index\" { node_type : { dataframe_index : heterodata_index}}\"\"\"\n",
    "    df = pd.read_csv(path, **kwargs,index_col=index_col)\n",
    "    node_types = df[type_col].unique()\n",
    "    mappings_dict = dict()\n",
    "    for node_type in node_types:\n",
    "        mapping = {index: i for i, index in enumerate(df[df[type_col] == node_type].index.unique())}\n",
    "        mappings_dict[node_type] = mapping\n",
    "\n",
    "    return df,mappings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'inner_product_decoder' object has no attribute '_load_state_dict_pre_hooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m eid \u001b[39m=\u001b[39m \u001b[39m34\u001b[39m\n\u001b[1;32m      5\u001b[0m date \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m18_04_23\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model,params \u001b[39m=\u001b[39m load_experiment(eid,date,train_data\u001b[39m.\u001b[39;49mmetadata())\n\u001b[1;32m      8\u001b[0m train_data \u001b[39m=\u001b[39m initialize_features(train_data,params[\u001b[39m\"\u001b[39m\u001b[39mfeature_type\u001b[39m\u001b[39m\"\u001b[39m],params[\u001b[39m\"\u001b[39m\u001b[39mfeature_dim\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m val_data \u001b[39m=\u001b[39m initialize_features(train_data,params[\u001b[39m\"\u001b[39m\u001b[39mfeature_type\u001b[39m\u001b[39m\"\u001b[39m],params[\u001b[39m\"\u001b[39m\u001b[39mfeature_dim\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m, in \u001b[0;36mload_experiment\u001b[0;34m(eid, date, metadata)\u001b[0m\n\u001b[1;32m     43\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(weights_path,map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(device))\n\u001b[1;32m     45\u001b[0m model \u001b[39m=\u001b[39m base_model(params,metadata)\n\u001b[0;32m---> 46\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(weights)\n\u001b[1;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m model,params\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2027\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2020\u001b[0m         out \u001b[39m=\u001b[39m hook(module, incompatible_keys)\n\u001b[1;32m   2021\u001b[0m         \u001b[39massert\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m, (\n\u001b[1;32m   2022\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mHooks registered with ``register_load_state_dict_post_hook`` are not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2023\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mexpected to return new values, if incompatible_keys need to be modified,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2024\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mit should be done inplace.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2025\u001b[0m         )\n\u001b[0;32m-> 2027\u001b[0m load(\u001b[39mself\u001b[39;49m, state_dict)\n\u001b[1;32m   2028\u001b[0m \u001b[39mdel\u001b[39;00m load\n\u001b[1;32m   2030\u001b[0m \u001b[39mif\u001b[39;00m strict:\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2015\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2013\u001b[0m         child_prefix \u001b[39m=\u001b[39m prefix \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2014\u001b[0m         child_state_dict \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m local_state_dict\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k\u001b[39m.\u001b[39mstartswith(child_prefix)}\n\u001b[0;32m-> 2015\u001b[0m         load(child, child_state_dict, child_prefix)\n\u001b[1;32m   2017\u001b[0m \u001b[39m# Note that the hook can modify missing_keys and unexpected_keys.\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m incompatible_keys \u001b[39m=\u001b[39m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2009\u001b[0m, in \u001b[0;36mModule.load_state_dict.<locals>.load\u001b[0;34m(module, local_state_dict, prefix)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(module, local_state_dict, prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   2008\u001b[0m     local_metadata \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m metadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m metadata\u001b[39m.\u001b[39mget(prefix[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], {})\n\u001b[0;32m-> 2009\u001b[0m     module\u001b[39m.\u001b[39;49m_load_from_state_dict(\n\u001b[1;32m   2010\u001b[0m         local_state_dict, prefix, local_metadata, \u001b[39mTrue\u001b[39;49;00m, missing_keys, unexpected_keys, error_msgs)\n\u001b[1;32m   2011\u001b[0m     \u001b[39mfor\u001b[39;00m name, child \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2012\u001b[0m         \u001b[39mif\u001b[39;00m child \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1908\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1875\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_state_dict\u001b[39m(\u001b[39mself\u001b[39m, state_dict, prefix, local_metadata, strict,\n\u001b[1;32m   1876\u001b[0m                           missing_keys, unexpected_keys, error_msgs):\n\u001b[1;32m   1877\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Copies parameters and buffers from :attr:`state_dict` into only\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m \u001b[39m    this module, but not its descendants. This is called on every submodule\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m \u001b[39m    in :meth:`~torch.nn.Module.load_state_dict`. Metadata saved for this\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1906\u001b[0m \u001b[39m            :meth:`~torch.nn.Module.load_state_dict`\u001b[39;00m\n\u001b[1;32m   1907\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1908\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_state_dict_pre_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m   1909\u001b[0m         hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\n\u001b[1;32m   1911\u001b[0m     persistent_buffers \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffers\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_non_persistent_buffers_set}\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'inner_product_decoder' object has no attribute '_load_state_dict_pre_hooks'"
     ]
    }
   ],
   "source": [
    "train_data,val_data = load_data(data_folder+\"split_dataset/\")\n",
    "full_data = torch.load(data_folder+\"split_dataset/full_dataset.pt\")\n",
    "\n",
    "eid = 34\n",
    "date = \"18_04_23\"\n",
    "model,params = load_experiment(eid,date,train_data.metadata())\n",
    "\n",
    "train_data = initialize_features(train_data,params[\"feature_type\"],params[\"feature_dim\"])\n",
    "val_data = initialize_features(train_data,params[\"feature_type\"],params[\"feature_dim\"])\n",
    "full_data = initialize_features(full_data,params[\"feature_type\"],params[\"feature_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "transf = T.ToSparseTensor(remove_edge_index=False)\n",
    "full_data = transf(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.x_dict\n",
    "adj_t = train_data.adj_t_dict\n",
    "edge_index = train_data.edge_index_dict\n",
    "edge_label_index = train_data.edge_label_index_dict\n",
    "# edge_label_index = train_data[\"gene_protein\",\"disease\"].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervision_types = [('gene_protein', 'gda', 'disease')]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    prediction = model(x,adj_t,edge_label_index,supervision_types,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='edge',\n",
    "        return_type='probs',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainer_forward(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = explainer.get_prediction(x,edge_index,edge_label_index,supervision_types,return_tensor=True)\n",
    "target = explainer.get_target(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3982, 0.7912, 0.8521,  ..., 0.4634, 0.0412, 0.0242])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor target dimension torch.Size([1, 26884]) is not valid. torch.Size([26884])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explainer(x,edge_index,edge_label_index\u001b[39m=\u001b[39;49medge_label_index,supervision_types\u001b[39m=\u001b[39;49msupervision_types,return_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    200\u001b[0m     x,\n\u001b[1;32m    201\u001b[0m     edge_index,\n\u001b[1;32m    202\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    203\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    204\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[39m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch_geometric/explain/algorithm/captum_explainer.py:162\u001b[0m, in \u001b[0;36mCaptumExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     target \u001b[39m=\u001b[39m target[index]\n\u001b[0;32m--> 162\u001b[0m attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattribution_method\u001b[39m.\u001b[39;49mattribute(\n\u001b[1;32m    163\u001b[0m     inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    164\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    165\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49madd_forward_args,\n\u001b[1;32m    166\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m node_mask, edge_mask \u001b[39m=\u001b[39m convert_captum_output(\n\u001b[1;32m    170\u001b[0m     attributions,\n\u001b[1;32m    171\u001b[0m     mask_type,\n\u001b[1;32m    172\u001b[0m     metadata,\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:274\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m internal_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     num_examples \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 274\u001b[0m     attributions \u001b[39m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[1;32m    277\u001b[0m         internal_batch_size,\n\u001b[1;32m    278\u001b[0m         n_steps,\n\u001b[1;32m    279\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    280\u001b[0m         baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m    281\u001b[0m         target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    282\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[1;32m    283\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[39m=\u001b[39mbaselines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/attr/_utils/batching.py:78\u001b[0m, in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m step_sizes \u001b[39m=\u001b[39m full_step_sizes[start_step:end_step]\n\u001b[1;32m     77\u001b[0m alphas \u001b[39m=\u001b[39m full_alphas[start_step:end_step]\n\u001b[0;32m---> 78\u001b[0m current_attr \u001b[39m=\u001b[39m attr_method\u001b[39m.\u001b[39;49m_attribute(\n\u001b[1;32m     79\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, n_steps\u001b[39m=\u001b[39;49mbatch_steps, step_sizes_and_alphas\u001b[39m=\u001b[39;49m(step_sizes, alphas)\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m total_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     total_attr \u001b[39m=\u001b[39m current_attr\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[39m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[39m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[39m=\u001b[39;49mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[39m=\u001b[39;49mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[39m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(n_steps, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(step_sizes)\u001b[39m.\u001b[39mview(n_steps, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(grad\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[39mfor\u001b[39;00m grad \u001b[39min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[39m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/_utils/common.py:487\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39m(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m additional_forward_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[0;32m--> 487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/_utils/common.py:506\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mgather(output, \u001b[39m1\u001b[39m, target\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(output), \u001b[39m1\u001b[39m))\n\u001b[1;32m    505\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    507\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor target dimension \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m is not valid. \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m             \u001b[39m%\u001b[39m (target\u001b[39m.\u001b[39mshape, output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    509\u001b[0m         )\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m num_examples, \u001b[39m\"\u001b[39m\u001b[39mTarget list length does not match output!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor target dimension torch.Size([1, 26884]) is not valid. torch.Size([26884])"
     ]
    }
   ],
   "source": [
    "explainer(x,edge_index,edge_label_index=edge_label_index,supervision_types=supervision_types,return_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IntegratedGradients' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer(x,edge_index,edge_label_index\u001b[39m=\u001b[39;49medge_label_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    200\u001b[0m     x,\n\u001b[1;32m    201\u001b[0m     edge_index,\n\u001b[1;32m    202\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    203\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    204\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[39m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/captum_explainer.py:153\u001b[0m, in \u001b[0;36mCaptumExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     metadata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     captum_model \u001b[39m=\u001b[39m CaptumModel(model, mask_type, index)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribution_method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattribution_method(captum_model)\n\u001b[1;32m    155\u001b[0m \u001b[39m# In captum, the target is the index for which\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m# the attribution is computed.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m ModelMode\u001b[39m.\u001b[39mregression:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'IntegratedGradients' object is not callable"
     ]
    }
   ],
   "source": [
    "explainer(x,edge_index,edge_label_index=edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IntegratedGradients' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer\u001b[39m.\u001b[39;49malgorithm\u001b[39m.\u001b[39;49mattribution_method()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'IntegratedGradients' object is not callable"
     ]
    }
   ],
   "source": [
    "explainer.algorithm.attribution_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IntegratedGradients' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer\u001b[39m.\u001b[39;49malgorithm(model,x,edge_index,edge_label_index\u001b[39m=\u001b[39;49medge_label_index,target\u001b[39m=\u001b[39;49mtarget,index\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/captum_explainer.py:153\u001b[0m, in \u001b[0;36mCaptumExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m     metadata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     captum_model \u001b[39m=\u001b[39m CaptumModel(model, mask_type, index)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribution_method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattribution_method(captum_model)\n\u001b[1;32m    155\u001b[0m \u001b[39m# In captum, the target is the index for which\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m# the attribution is computed.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m ModelMode\u001b[39m.\u001b[39mregression:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'IntegratedGradients' object is not callable"
     ]
    }
   ],
   "source": [
    "explainer.algorithm(model,x,edge_index,edge_label_index=edge_label_index,target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain.algorithm.captum import CaptumHeteroModel\n",
    "from torch_geometric.nn import to_captum_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_model = to_captum_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<captum.attr._core.integrated_gradients.IntegratedGradients at 0x7f00e998d5a0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.algorithm.attribution_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IntegratedGradients' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer\u001b[39m.\u001b[39;49malgorithm\u001b[39m.\u001b[39;49mattribution_method()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'IntegratedGradients' object is not callable"
     ]
    }
   ],
   "source": [
    "explainer.algorithm.attribution_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.algorithm.supports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Explainer.__call__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer(x,adj_t,edge_index)\n",
      "\u001b[0;31mTypeError\u001b[0m: Explainer.__call__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "explainer(x,adj_t,edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor target dimension torch.Size([1, 26884]) is not valid. torch.Size([1, 26884])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m explainer(x,edge_index,edge_label_index\u001b[39m=\u001b[39;49medge_label_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    200\u001b[0m     x,\n\u001b[1;32m    201\u001b[0m     edge_index,\n\u001b[1;32m    202\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    203\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    204\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[39m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/algorithm/captum_explainer.py:162\u001b[0m, in \u001b[0;36mCaptumExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     target \u001b[39m=\u001b[39m target[index]\n\u001b[0;32m--> 162\u001b[0m attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattribution_method\u001b[39m.\u001b[39;49mattribute(\n\u001b[1;32m    163\u001b[0m     inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    164\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    165\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49madd_forward_args,\n\u001b[1;32m    166\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m node_mask, edge_mask \u001b[39m=\u001b[39m convert_captum_output(\n\u001b[1;32m    170\u001b[0m     attributions,\n\u001b[1;32m    171\u001b[0m     mask_type,\n\u001b[1;32m    172\u001b[0m     metadata,\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:274\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m internal_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     num_examples \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 274\u001b[0m     attributions \u001b[39m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[1;32m    277\u001b[0m         internal_batch_size,\n\u001b[1;32m    278\u001b[0m         n_steps,\n\u001b[1;32m    279\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    280\u001b[0m         baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m    281\u001b[0m         target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    282\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[1;32m    283\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[39m=\u001b[39mbaselines,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    293\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/attr/_utils/batching.py:78\u001b[0m, in \u001b[0;36m_batch_attribution\u001b[0;34m(attr_method, num_examples, internal_batch_size, n_steps, include_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m step_sizes \u001b[39m=\u001b[39m full_step_sizes[start_step:end_step]\n\u001b[1;32m     77\u001b[0m alphas \u001b[39m=\u001b[39m full_alphas[start_step:end_step]\n\u001b[0;32m---> 78\u001b[0m current_attr \u001b[39m=\u001b[39m attr_method\u001b[39m.\u001b[39;49m_attribute(\n\u001b[1;32m     79\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, n_steps\u001b[39m=\u001b[39;49mbatch_steps, step_sizes_and_alphas\u001b[39m=\u001b[39;49m(step_sizes, alphas)\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m total_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     total_attr \u001b[39m=\u001b[39m current_attr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[39m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[39m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[39m=\u001b[39;49mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[39m=\u001b[39;49mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[39m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(n_steps, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(step_sizes)\u001b[39m.\u001b[39mview(n_steps, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(grad\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[39mfor\u001b[39;00m grad \u001b[39min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[39m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/_utils/common.py:487\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39m(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m additional_forward_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[0;32m--> 487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/captum/_utils/common.py:506\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mgather(output, \u001b[39m1\u001b[39m, target\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(output), \u001b[39m1\u001b[39m))\n\u001b[1;32m    505\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    507\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTensor target dimension \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m is not valid. \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m             \u001b[39m%\u001b[39m (target\u001b[39m.\u001b[39mshape, output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    509\u001b[0m         )\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m num_examples, \u001b[39m\"\u001b[39m\u001b[39mTarget list length does not match output!\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor target dimension torch.Size([1, 26884]) is not valid. torch.Size([1, 26884])"
     ]
    }
   ],
   "source": [
    "explainer(x,edge_index,edge_label_index=edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'x_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_config \u001b[39m=\u001b[39m ModelConfig(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_classification\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     task_level\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     return_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m explainer \u001b[39m=\u001b[39m Explainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model,  \u001b[39m# It is assumed that model outputs a single tensor.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     algorithm\u001b[39m=\u001b[39mCaptumExplainer(\u001b[39m'\u001b[39m\u001b[39mIntegratedGradients\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model_config \u001b[39m=\u001b[39m model_config\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m hetero_explanation \u001b[39m=\u001b[39m explainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     train_data\u001b[39m.\u001b[39;49mx_dict,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     train_data\u001b[39m.\u001b[39;49medge_index_dict,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     index\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(hetero_explanation\u001b[39m.\u001b[39medge_mask_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ingrid/Documents/tesis/gcnn_gdas/exploration/model_exploration/testing_explainers.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(hetero_explanation\u001b[39m.\u001b[39mnode_mask_dict)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:192\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    190\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should not be provided for the explanation \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplanation_type\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prediction(x, edge_index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_target(prediction)\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/explain/explainer.py:115\u001b[0m, in \u001b[0;36mExplainer.get_prediction\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 115\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/exploration/model_exploration/../../src/models/base_model.py:197\u001b[0m, in \u001b[0;36mbase_model.forward\u001b[0;34m(self, data, supervision_types)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,data,supervision_types):\n\u001b[0;32m--> 197\u001b[0m     x \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mx_dict\n\u001b[1;32m    198\u001b[0m     adj_t \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39madj_t_dict\n\u001b[1;32m    199\u001b[0m     edge_label_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_label_index_dict\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'x_dict'"
     ]
    }
   ],
   "source": [
    "model_config = ModelConfig(\n",
    "    mode='binary_classification',\n",
    "    task_level='edge',\n",
    "    return_type='raw',\n",
    ")\n",
    "\n",
    "explainer = Explainer(\n",
    "    model,  # It is assumed that model outputs a single tensor.\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config = model_config\n",
    ")\n",
    "\n",
    "hetero_explanation = explainer(\n",
    "    train_data.x_dict,\n",
    "    train_data.edge_index_dict,\n",
    "    index=torch.tensor([1, 3]),\n",
    ")\n",
    "print(hetero_explanation.edge_mask_dict)\n",
    "print(hetero_explanation.node_mask_dict)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import training_utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import SAGEConv,GATConv, to_hetero\n",
    "\n",
    "class inner_product_decoder(torch.nn.Module):\n",
    "    def forward(self,x_dict,edge_label_index,supervision_types,apply_sigmoid=True):\n",
    "        pred_dict = {}\n",
    "        for edge_type in supervision_types:\n",
    "            edge_index = edge_label_index[edge_type]\n",
    "\n",
    "            src_type = edge_type[0]\n",
    "            trg_type = edge_type[2]\n",
    "\n",
    "            x_src = x_dict[src_type]\n",
    "            x_trg = x_dict[trg_type]\n",
    "\n",
    "            nodes_src = x_src[edge_index[0]]\n",
    "            nodes_trg = x_trg[edge_index[1]]\n",
    "            pred = (nodes_src * nodes_trg).sum(dim=-1)\n",
    "\n",
    "        if apply_sigmoid:\n",
    "            pred = torch.sigmoid(pred)\n",
    "\n",
    "        pred_dict[edge_type] = pred\n",
    "        \n",
    "        return pred_dict\n",
    "\n",
    "class base_message_layer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model_params,hidden_layer=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Currently SageConv or GATConv, might have to modify this to support other Convs\n",
    "        conv_type = model_params[\"conv_type\"]\n",
    "        self.conv = layer_dict[conv_type]((-1,-1), model_params[\"hidden_channels\"],aggr=model_params[\"micro_aggregation\"],add_self_loops=False)\n",
    "        self.normalize = model_params[\"L2_norm\"]\n",
    "\n",
    "        post_conv_modules = []\n",
    "        if model_params[\"batch_norm\"]:\n",
    "            bn = torch.nn.BatchNorm1d(model_params[\"hidden_channels\"])\n",
    "            post_conv_modules.append(bn)\n",
    "        \n",
    "        if model_params[\"dropout\"] > 0:    \n",
    "            dropout = torch.nn.Dropout(p=model_params[\"dropout\"])\n",
    "            post_conv_modules.append(dropout)\n",
    "        \n",
    "        # No activation on final embedding layer\n",
    "        if hidden_layer:\n",
    "            activation = model_params[\"activation\"]()\n",
    "            post_conv_modules.append(activation)\n",
    "        \n",
    "        self.post_conv = torch.nn.Sequential(*post_conv_modules)\n",
    "\n",
    "    def forward(self, x:dict, edge_index:dict) -> dict:\n",
    "        x = self.conv(x,edge_index)\n",
    "        x = self.post_conv(x)\n",
    "        if self.normalize:\n",
    "            x = torch.nn.functional.normalize(x,2,-1)\n",
    "        return x\n",
    "\n",
    "class multilayer_message_passing(torch.nn.Module):\n",
    "    #TODO: consider input and output dims with skipcat. Currently the two supported convs auto-detect dimensions. Might have to modify this if i add more convs in the future.\n",
    "    def __init__(self,num_layers,model_params,metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.skip = model_params[\"layer_connectivity\"]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            hidden_layer = i != self.num_layers-1\n",
    "            layer = to_hetero(base_message_layer(model_params,hidden_layer),metadata,model_params[\"macro_aggregation\"])\n",
    "            self.add_module(f\"Layer_{i}\",layer)\n",
    "    \n",
    "    def hetero_skipsum(self,x: dict, x_i:dict) -> dict:\n",
    "        x_transformed = {}\n",
    "        for key,x_val in x.items():\n",
    "            x_i_val = x_i[key]\n",
    "            transformed_val = x_val + x_i_val\n",
    "            x_transformed[key] = transformed_val\n",
    "\n",
    "        return x_transformed\n",
    "\n",
    "    def hetero_skipcat(self,x: dict, x_i:dict) -> dict:\n",
    "        x_transformed = {}\n",
    "        for key,x_val in x.items():\n",
    "            x_i_val = x_i[key]\n",
    "            transformed_val = torch.cat([x_val,x_i_val],dim=-1)\n",
    "            x_transformed[key] = transformed_val\n",
    "\n",
    "        return x_transformed\n",
    "    \n",
    "    def forward(self, x:dict, edge_index:dict) -> dict:\n",
    "        for i, layer in enumerate(self.children()):\n",
    "            x_i = x\n",
    "            x = layer(x,edge_index)\n",
    "            if self.skip == \"skipsum\":\n",
    "                x = self.hetero_skipsum(x,x_i)\n",
    "            elif self.skip == \"skipcat\" and i < self.num_layers -1:\n",
    "                x = self.hetero_skipcat(x,x_i)\n",
    "        \n",
    "        return x \n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self,num_layers,in_dim,out_dim,model_params,hidden_dim=None):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim = out_dim if hidden_dim is None else hidden_dim\n",
    "        \n",
    "        modules = []\n",
    "        if num_layers == 1:\n",
    "            modules.append(torch.nn.Linear(in_dim,out_dim))\n",
    "        else:\n",
    "            for i in range(num_layers):\n",
    "                final_layer = i == num_layers-1\n",
    "                first_layer = i == 0\n",
    "                if first_layer:\n",
    "                    modules.append(torch.nn.Linear(in_dim,hidden_dim))\n",
    "                    modules.append(model_params[\"activation\"]())\n",
    "                elif final_layer:\n",
    "                    modules.append(torch.nn.Linear(hidden_dim,out_dim))\n",
    "                else:\n",
    "                    modules.append(torch.nn.Linear(hidden_dim,hidden_dim))\n",
    "                    modules.append(model_params[\"activation\"]())\n",
    "        \n",
    "        self.model = torch.nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class base_encoder(torch.nn.Module):\n",
    "    def __init__(self,model_params,metadata):\n",
    "        super().__init__()\n",
    "\n",
    "        self.has_pre_mlp = model_params[\"pre_process_layers\"] > 0\n",
    "        self.has_post_mlp = model_params[\"post_process_layers\"] > 0\n",
    "\n",
    "        if self.has_pre_mlp:\n",
    "            self.pre_mlp = to_hetero(MLP(model_params[\"pre_process_layers\"],model_params[\"feature_dim\"],model_params[\"hidden_channels\"],model_params),metadata)\n",
    "        \n",
    "        self.message_passing = multilayer_message_passing(model_params[\"msg_passing_layers\"],model_params,metadata)\n",
    "\n",
    "        if self.has_post_mlp:\n",
    "            self.post_mlp = to_hetero(MLP(model_params[\"post_process_layers\"],model_params[\"hidden_channels\"],model_params[\"hidden_channels\"],model_params),metadata)\n",
    "    \n",
    "    def forward(self,x:dict,edge_index:dict) -> dict :\n",
    "        if self.has_pre_mlp:\n",
    "            x = self.pre_mlp(x)\n",
    "\n",
    "        x = self.message_passing(x,edge_index)\n",
    "        \n",
    "        if self.has_post_mlp:\n",
    "            x = self.post_mlp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class base_model_test(torch.nn.Module):\n",
    "    def __init__(self, model_params,metadata,supervision_types = [('gene_protein', 'gda', 'disease')]):\n",
    "        super().__init__()\n",
    "\n",
    "        default_model_params = {\n",
    "            \"hidden_channels\":32,\n",
    "            \"conv_type\":\"SAGEConv\",\n",
    "            \"batch_norm\": True,\n",
    "            \"dropout\":0,\n",
    "            \"activation\":torch.nn.LeakyReLU,\n",
    "            \"micro_aggregation\":\"mean\",\n",
    "            \"macro_aggregation\":\"mean\",\n",
    "            \"layer_connectivity\":None,\n",
    "            \"L2_norm\":False,\n",
    "            \"feature_dim\": 10,\n",
    "            \"pre_process_layers\":0,\n",
    "            \"msg_passing_layers\":2,\n",
    "            \"post_process_layers\":0,\n",
    "        }\n",
    "        \n",
    "        for arg in default_model_params:\n",
    "            if arg not in model_params:\n",
    "                model_params[arg] = default_model_params[arg]\n",
    "        \n",
    "        self.encoder = base_encoder(model_params,metadata)\n",
    "        self.decoder = inner_product_decoder()\n",
    "        self.loss_fn = torch.nn.BCELoss()\n",
    "        self.supervision_types = supervision_types\n",
    "    \n",
    "    def forward(self,x,adj_t,edge_label_index,return_tensor=True):\n",
    "        \"\"\"adj_t_dict or edge_index_dict are valid options. adj_t is recommended for training\"\"\"\n",
    "\n",
    "        x = self.encoder(x,adj_t)\n",
    "        pred = self.decoder(x,edge_label_index,self.supervision_types)\n",
    "\n",
    "        if return_tensor:\n",
    "            pred = pred[supervision_types[0]]\n",
    "        return pred\n",
    "\n",
    "    def loss(self, prediction, labels):\n",
    "        loss = 0\n",
    "\n",
    "        if type(prediction) == dict:\n",
    "            for edge_type,pred in prediction.items():\n",
    "                y = labels[edge_type]\n",
    "                loss += self.loss_fn(pred, y.type(pred.dtype))\n",
    "        else:\n",
    "            y = labels[self.supervision_types[0]]\n",
    "            loss += self.loss_fn(prediction, y.type(prediction.dtype))\n",
    "\n",
    "        return loss\n",
    "\n",
    "layer_dict = {\n",
    "    \"GATConv\":GATConv,\n",
    "    \"SAGEConv\":SAGEConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,val_data = load_data(data_folder+\"split_dataset/\")\n",
    "full_data = torch.load(data_folder+\"split_dataset/full_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_channels': 32,\n",
    " 'conv_type': \"SAGEConv\",\n",
    " 'batch_norm': True,\n",
    " 'dropout': 0.1,\n",
    " 'activation': torch.nn.LeakyReLU,\n",
    " 'micro_aggregation': 'sum',\n",
    " 'macro_aggregation': 'sum',\n",
    " 'layer_connectivity': None,\n",
    " 'L2_norm': True,\n",
    " 'pre_process_layers': 0,\n",
    " 'msg_passing_layers': 2,\n",
    " 'post_process_layers': 0,\n",
    " 'feature_dim': 10,\n",
    " 'feature_type': 'ones',\n",
    " 'weight_decay': 0.001,\n",
    " 'lr': 0.001,\n",
    " 'epochs': 100,\n",
    " 'patience': 5,\n",
    " 'delta': 0.01}\n",
    "\n",
    "train_set = initialize_features(train_data,params[\"feature_type\"],params[\"feature_dim\"])\n",
    "val_set = initialize_features(train_data,params[\"feature_type\"],params[\"feature_dim\"])\n",
    "full_data = initialize_features(full_data,params[\"feature_type\"],params[\"feature_dim\"])\n",
    "\n",
    "model = base_model_test(params,train_set.metadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(heterodata):\n",
    "    x = heterodata.x_dict\n",
    "    adj_t = heterodata.adj_t_dict\n",
    "    edge_label_index = heterodata.edge_label_index_dict\n",
    "    edge_label = heterodata.edge_label_dict\n",
    "\n",
    "    return x,adj_t,edge_label_index,edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def hits_at_k(y_true,x_prob,k,key) -> dict:\n",
    "    \"\"\"Dados los tensores x_prob y edge_label, calcula cuantas predicciones hizo correctamente en los primeros k puntajes.\n",
    "    x_prob es la predicción del modelo luego de aplicar sigmoid (sin redondear, osea, el puntaje crudo)\"\"\"\n",
    "\n",
    "    #ordeno los puntajes de mayor a menor\n",
    "    x_prob, indices = torch.sort(x_prob, descending=True)\n",
    "\n",
    "    #me quedo solo con los k mayor punteados\n",
    "    x_prob = x_prob[:k]\n",
    "    indices = indices[:k]\n",
    "\n",
    "    if any(x_prob < 0.5):\n",
    "      threshold_index = (x_prob < 0.5).nonzero()[0].item()\n",
    "      print(f\"Top {k} scores for {key} below classification threshold 0.5, threshold index: {threshold_index}\")\n",
    "\n",
    "    #busco que label tenían esas k preds\n",
    "    labels = y_true[indices]\n",
    "\n",
    "    #cuento cuantas veces predije uno positivo en el top k\n",
    "    hits = labels.sum().item()\n",
    "\n",
    "    return hits\n",
    "\n",
    "def train(model, optimizer, graph):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x,adj_t,edge_label_index,edge_label = get_input(graph)\n",
    "\n",
    "    preds = model(x,adj_t,edge_label_index)\n",
    "    loss = model.loss(preds, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_val_loss(model,val_data):\n",
    "    model.eval()\n",
    "    x,adj_t,edge_label_index,edge_label = get_input(val_data)\n",
    "    \n",
    "    preds = model(x,adj_t,edge_label_index)\n",
    "    loss = model.loss(preds, edge_label)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def get_metrics(y_true, x_pred):\n",
    "   acc = round(accuracy_score(y_true,x_pred),2)\n",
    "   ap = round(average_precision_score(y_true, x_pred),2)\n",
    "   roc_auc = round(roc_auc_score(y_true,x_pred),2)\n",
    "\n",
    "   return acc,ap ,roc_auc\n",
    "  \n",
    "@torch.no_grad()\n",
    "def test(model,data,metric):\n",
    "  model.eval()\n",
    "  x,adj_t,edge_label_index,edge_label = get_input(data)\n",
    "  \n",
    "  preds = model(x,adj_t,edge_label_index)\n",
    "\n",
    "  if type(preds) == dict:\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    for key,pred in preds.items():\n",
    "        pred_label = torch.round(pred)\n",
    "        ground_truth = edge_label[key]\n",
    "        all_preds.append(pred_label)\n",
    "        all_true.append(ground_truth)\n",
    "    total_predictions = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "    total_true = torch.cat(all_true, dim=0).cpu().numpy()\n",
    "    score = metric(total_true,total_predictions)\n",
    "  else:\n",
    "    pred_label = torch.round(preds)\n",
    "    ground_truth = edge_label[model.supervision_types[0]]\n",
    "    score = metric(ground_truth,pred_label)\n",
    "  return score\n",
    "  \n",
    "\n",
    "@torch.no_grad()\n",
    "def full_test(model,data,k,global_score=True):\n",
    "  model.eval()\n",
    "  x,adj_t,edge_label_index,edge_label = get_input(data)\n",
    "\n",
    "  preds = model(x,adj_t,edge_label_index)\n",
    "  metrics = {}\n",
    "\n",
    "  if global_score:\n",
    "    all_scores = []\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    for key,pred in preds.items():\n",
    "        pred_label = torch.round(pred)\n",
    "        ground_truth = edge_label[key]\n",
    "        all_scores.append(pred)\n",
    "        all_preds.append(pred_label)\n",
    "        all_true.append(ground_truth)\n",
    "\n",
    "    total_predictions = torch.cat(all_preds, dim=0)\n",
    "    total_true = torch.cat(all_true, dim=0)\n",
    "    total_scores = torch.cat(all_scores,dim=0)\n",
    "\n",
    "    acc, ap, roc_auc =  get_metrics(total_true.cpu().numpy(), total_predictions.cpu().numpy())\n",
    "    hits_k = hits_at_k(total_true,total_scores,k,\"all\")\n",
    "    metrics[\"all\"] = [acc,ap,roc_auc,hits_k]\n",
    "\n",
    "  else:\n",
    "    for key,pred in preds.items():\n",
    "        pred_label = torch.round(pred)\n",
    "        ground_truth = edge_label_index[key]\n",
    "        acc, ap, roc_auc = get_metrics(ground_truth.cpu().numpy(), pred_label.cpu().numpy())\n",
    "        hits_k = hits_at_k(ground_truth,pred,k,key)\n",
    "        metrics[key] = [acc,ap, roc_auc,hits_k]\n",
    "  \n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5303047299385071\n",
      "0.4939281940460205\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], weight_decay=params[\"weight_decay\"])\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_scores = []\n",
    "val_scores = []\n",
    "\n",
    "metric = roc_auc_score\n",
    "epochs = params[\"epochs\"]\n",
    "\n",
    "early_stopper = util.EarlyStopper(params[\"patience\"],params[\"delta\"])\n",
    "for epoch in range(epochs):\n",
    "    supervision_types = model.supervision_types\n",
    "    train_loss = train(model,optimizer,train_set)\n",
    "    val_loss = get_val_loss(model,val_set)\n",
    "    train_score = test(model,train_set,metric)\n",
    "    val_score = test(model,val_set,metric)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_scores.append(train_score)\n",
    "    val_scores.append(val_score)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if epoch%50 == 0:\n",
    "        print(train_loss)\n",
    "    \n",
    "    if early_stopper.early_stop(val_loss):\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "val_auc = test(model,val_set,roc_auc_score)\n",
    "curve_data = [train_losses,val_losses,train_scores,val_scores]\n",
    "\n",
    "util.plot_training_stats(\"Trying explainers\", *curve_data,\"AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='binary_classification',\n",
    "        task_level='edge',\n",
    "        return_type='probs',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,adj_t,edge_label_index,edge_label = get_input(train_set)\n",
    "edge_index = train_set.edge_index_dict\n",
    "supervision_types = model.supervision_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    pred = model(x,adj_t,edge_label_index)\n",
    "    target = torch.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dimension 0 of input should be 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m inputs, additional_forward_args \u001b[39m=\u001b[39m to_captum_input(data\u001b[39m.\u001b[39mx_dict,\n\u001b[1;32m     18\u001b[0m                                     data\u001b[39m.\u001b[39medge_index_dict, mask_type)\n\u001b[1;32m     20\u001b[0m ig \u001b[39m=\u001b[39m IntegratedGradients(captum_model)\n\u001b[0;32m---> 21\u001b[0m ig_attr \u001b[39m=\u001b[39m ig\u001b[39m.\u001b[39;49mattribute(inputs\u001b[39m=\u001b[39;49minputs)\n\u001b[1;32m     22\u001b[0m edge_attr_dict \u001b[39m=\u001b[39m captum_output_to_dicts(ig_attr, mask_type, metadata)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[39m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[39m=\u001b[39;49mbaselines,\n\u001b[1;32m    289\u001b[0m         target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    290\u001b[0m         additional_forward_args\u001b[39m=\u001b[39;49madditional_forward_args,\n\u001b[1;32m    291\u001b[0m         n_steps\u001b[39m=\u001b[39;49mn_steps,\n\u001b[1;32m    292\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[39m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[39m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[39m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[39m=\u001b[39;49mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[39m=\u001b[39;49mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[39m=\u001b[39;49minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[39m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[39m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(n_steps, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtensor(step_sizes)\u001b[39m.\u001b[39mview(n_steps, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(grad\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[39mfor\u001b[39;00m grad \u001b[39min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[39m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[39m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[39massert\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTarget not provided when necessary, cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m take gradient with respect to multiple outputs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/captum/_utils/common.py:482\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    479\u001b[0m inputs \u001b[39m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    480\u001b[0m additional_forward_args \u001b[39m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 482\u001b[0m output \u001b[39m=\u001b[39m forward_func(\n\u001b[1;32m    483\u001b[0m     \u001b[39m*\u001b[39;49m(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49madditional_forward_args)\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;49;00m additional_forward_args \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;49;00m inputs\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    487\u001b[0m \u001b[39mreturn\u001b[39;00m _select_targets(output, target)\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/tesis/gcnn_gdas/venv/lib/python3.10/site-packages/torch_geometric/explain/algorithm/captum.py:44\u001b[0m, in \u001b[0;36mCaptumModel.forward\u001b[0;34m(self, mask, *args)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# The mask tensor, which comes from Captum's attribution methods,\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# contains the number of samples in dimension 0. Since we are\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# working with only one sample, we squeeze the tensors below.\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39massert\u001b[39;00m mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDimension 0 of input should be 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask_type \u001b[39m==\u001b[39m MaskLevelType\u001b[39m.\u001b[39medge:\n\u001b[1;32m     46\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mExpects at least x and edge_index as args.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dimension 0 of input should be 1"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv\n",
    "from torch_geometric.nn import (captum_output_to_dicts,\n",
    "                                to_captum_model, to_captum_input)\n",
    "\n",
    "data = train_set\n",
    "y = target\n",
    "...  # Train the model.\n",
    "\n",
    "# Explain predictions for node `10`:\n",
    "mask_type=\"edge\"\n",
    "metadata = data.metadata()\n",
    "output_idx = 10\n",
    "captum_model = to_captum_model(model, mask_type, metadata)\n",
    "inputs, additional_forward_args = to_captum_input(data.x_dict,\n",
    "                                    data.edge_index_dict, mask_type)\n",
    "\n",
    "ig = IntegratedGradients(captum_model)\n",
    "ig_attr = ig.attribute(inputs=inputs)\n",
    "edge_attr_dict = captum_output_to_dicts(ig_attr, mask_type, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 53770]),\n",
       " torch.Size([1, 27292]),\n",
       " torch.Size([1, 140866]),\n",
       " torch.Size([1, 53770]),\n",
       " torch.Size([1, 27292]),\n",
       " torch.Size([1, 5217]),\n",
       " torch.Size([1, 10032]),\n",
       " torch.Size([1, 1208]),\n",
       " torch.Size([1, 1208]),\n",
       " torch.Size([1, 5217]),\n",
       " torch.Size([1, 576])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 53770]),\n",
       " torch.Size([2, 27292]),\n",
       " torch.Size([2, 140866]),\n",
       " torch.Size([2, 53770]),\n",
       " torch.Size([2, 27292]),\n",
       " torch.Size([2, 5217]),\n",
       " torch.Size([2, 10032]),\n",
       " torch.Size([2, 1208]),\n",
       " torch.Size([2, 1208]),\n",
       " torch.Size([2, 5217]),\n",
       " torch.Size([2, 576])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in edge_index.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    73,   449,  ...,   591,   195,     3],\n",
       "        [    0,     3,     3,  ..., 17317, 17320, 17321]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index_dict[('disease', 'gda', 'gene_protein')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease__gda__gene_protein\n",
      "pathway__pathway_protein__gene_protein\n",
      "gene_protein__ppi__gene_protein\n",
      "gene_protein__gda__disease\n",
      "gene_protein__pathway_protein__pathway\n",
      "bert_group__disease_disease__disease\n",
      "disease__disease_disease__disease\n",
      "complex__form_complex__gene_protein\n",
      "gene_protein__form_complex__complex\n",
      "disease__disease_disease__bert_group\n",
      "bert_group__disease_disease__bert_group\n",
      "disease__gda__gene_protein\n",
      "pathway__pathway_protein__gene_protein\n",
      "gene_protein__ppi__gene_protein\n",
      "gene_protein__gda__disease\n",
      "gene_protein__pathway_protein__pathway\n",
      "bert_group__disease_disease__disease\n",
      "disease__disease_disease__disease\n",
      "complex__form_complex__gene_protein\n",
      "gene_protein__form_complex__complex\n",
      "disease__disease_disease__bert_group\n",
      "bert_group__disease_disease__bert_group\n"
     ]
    }
   ],
   "source": [
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.ModuleDict):\n",
    "        for edge_type in edge_types:\n",
    "            # TODO (jinu) Use common function get `str_edge_type`.\n",
    "            str_edge_type = '__'.join(edge_type)\n",
    "            if str_edge_type in module:\n",
    "                print(str_edge_type)\n",
    "                # set_masks(\n",
    "                #     module[str_edge_type],\n",
    "                #     mask_dict[edge_type],\n",
    "                #     edge_index_dict[edge_type],\n",
    "                #     apply_sigmoid=apply_sigmoid,\n",
    "                # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x7f9f477460a0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (disease__gda__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (pathway__pathway_protein__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__ppi__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__gda__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__pathway_protein__pathway): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (bert_group__disease_disease__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (disease__disease_disease__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (complex__form_complex__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__form_complex__complex): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (disease__disease_disease__bert_group): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (bert_group__disease_disease__bert_group): SAGEConv((-1, -1), 32, aggr=sum)\n",
      ")\n",
      "ModuleDict(\n",
      "  (disease__gda__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (pathway__pathway_protein__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__ppi__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__gda__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__pathway_protein__pathway): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (bert_group__disease_disease__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (disease__disease_disease__disease): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (complex__form_complex__gene_protein): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (gene_protein__form_complex__complex): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (disease__disease_disease__bert_group): SAGEConv((-1, -1), 32, aggr=sum)\n",
      "  (bert_group__disease_disease__bert_group): SAGEConv((-1, -1), 32, aggr=sum)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.ModuleDict):\n",
    "        if any([isinstance(submodule, MessagePassing) for submodule in module.modules()]):\n",
    "            print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    73,   449,  ...,   591,   195,     3],\n",
       "        [    0,     3,     3,  ..., 17317, 17320, 17321]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index[('disease', 'gda', 'gene_protein')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gene_protein',\n",
       "  'ppi',\n",
       "  'gene_protein'): tensor([[ 2273,  6410,  6484,  ..., 13032,   373,  1754],\n",
       "         [ 4571,  6415, 15631,  ...,  8002,  1884,  8391]]),\n",
       " ('gene_protein',\n",
       "  'gda',\n",
       "  'disease'): tensor([[ 2929,  6037,  4913,  ...,  3391, 15286,  7687],\n",
       "         [  870,  4171,  4728,  ...,  7081,  7141, 11498]]),\n",
       " ('gene_protein',\n",
       "  'pathway_protein',\n",
       "  'pathway'): tensor([[ 9712,  4875,  4179,  ..., 13283,  4048, 13984],\n",
       "         [ 1187,   346,  1114,  ...,  1427,  1433,   357]]),\n",
       " ('disease',\n",
       "  'disease_disease',\n",
       "  'disease'): tensor([[  657,  1656, 11957,  ..., 13357, 12671,  9112],\n",
       "         [14177,  8655, 14882,  ...,  6576,   112,  8946]]),\n",
       " ('gene_protein',\n",
       "  'form_complex',\n",
       "  'complex'): tensor([[ 5333,   300,  2020,  ..., 11341, 16312,  6904],\n",
       "         [   10,   116,    45,  ...,   154,   112,   309]]),\n",
       " ('disease',\n",
       "  'disease_disease',\n",
       "  'bert_group'): tensor([[  603,  7474,  8560,  ..., 13647, 12388, 13596],\n",
       "         [  654,   622,   791,  ...,   210,   945,   756]]),\n",
       " ('bert_group',\n",
       "  'disease_disease',\n",
       "  'bert_group'): tensor([[ 251,   44,  457,  145,   79,  132,  191,  703,  284,  631,  211,    0,\n",
       "           107,   97,   88,  174,  182,   83,  304,  674,  475,  605,    0,  111,\n",
       "           377,  342,  331,  372,  445,  197,  112,   48,  594,  106,  138,  313,\n",
       "           284,    1,   32,  223,  353,  132,   79,  270,   30,   48,   50,  252,\n",
       "           284,    0,    0,   91,  226,  663,  512,  194,  342,    0,  555,   79,\n",
       "           104,  286,  705,    7,  660,  622,  413,   29,   77,   44,  608,  251,\n",
       "          1032,  424,  905,  843,  656, 1007,  563, 1000,  159,  604,   39,  374,\n",
       "           120,  611,  551,  957,    5,  436,  252,  676,  262,  786,  140,  249,\n",
       "           479,   36,  438,  277,  965,  609,  953,  618,  459,  555,  300,  970,\n",
       "           989,  486,  468,  190,  909,  530,  465,  285,  722,  849, 1001,  943,\n",
       "           418,  590,  373,  809, 1037,  831, 1003,   12,  884,  363,  680,   75,\n",
       "           953,  875,  114,  757,   28,  553,   45,  558,  155,  457,  839,  850],\n",
       "         [ 530,   46,  458,  146,  281,  134,  226,  704,  286,  689,  299,    2,\n",
       "           108,   98,  114,  175,  183,  125,  634,  675,  476,  606,    8,  165,\n",
       "           378,  343,  333,  373,  446,  198,  113,  222,  595,  342,  609,  707,\n",
       "           288,  343,   33,  263,  592,  133,  296,  764,   60,  223,  123,  253,\n",
       "           285,    1,   11,  326,  299,  666,  513,  196,  344,   10,  577,  193,\n",
       "           506,  288,  706,   83,  661,  623,  414,   30,   78,   48,  641,  556,\n",
       "           568,  501,  280,  285,  252,  744,  859,   19,  446, 1026,   49,  291,\n",
       "           371,  474,  278,  462,  441,  160,   66,  187,  849,  664,  521, 1030,\n",
       "           377,   64,  431,  108,  708,  350,  445,  415,  963,  106,  395,  472,\n",
       "           761,   58,  566,  638,  110,  591,  714,  702,  488,  393,  971,  897,\n",
       "           197,  458,  762,  428,  647,  768,  373,  221,  684,  973,  422,  959,\n",
       "           934,  431, 1026,  900,  923,  791,   14,  387,  624,  702,   83,  614]])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch_geometric.explain.algorithm.utils import (\n",
    "    clear_masks,\n",
    "    set_hetero_masks,\n",
    ")\n",
    "from torch_geometric.nn import GCNConv, HeteroConv, SAGEConv, to_hetero\n",
    "\n",
    "\n",
    "class HeteroModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('paper', 'to', 'paper'):\n",
    "            GCNConv(-1, 32),\n",
    "            ('author', 'to', 'paper'):\n",
    "            SAGEConv((-1, -1), 32),\n",
    "            ('paper', 'to', 'author'):\n",
    "            SAGEConv((-1, -1), 32),\n",
    "        })\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('paper', 'to', 'paper'):\n",
    "            GCNConv(-1, 32),\n",
    "            ('author', 'to', 'paper'):\n",
    "            SAGEConv((-1, -1), 32),\n",
    "            ('paper', 'to', 'author'):\n",
    "            SAGEConv((-1, -1), 32),\n",
    "        })\n",
    "\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), 32)\n",
    "        self.conv2 = SAGEConv((-1, -1), 32)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "def test_set_clear_mask(hetero_data):\n",
    "    edge_mask_dict = {\n",
    "        ('paper', 'to', 'paper'): torch.ones(200),\n",
    "        ('author', 'to', 'paper'): torch.ones(100),\n",
    "        ('paper', 'to', 'author'): torch.ones(100),\n",
    "    }\n",
    "\n",
    "    model = HeteroModel()\n",
    "\n",
    "    set_hetero_masks(model, edge_mask_dict, hetero_data.edge_index_dict)\n",
    "    for edge_type in hetero_data.edge_types:\n",
    "        # Check that masks are correctly set:\n",
    "        str_edge_type = '__'.join(edge_type)\n",
    "        assert torch.allclose(model.conv1.convs[str_edge_type]._edge_mask,\n",
    "                              edge_mask_dict[edge_type])\n",
    "        assert model.conv1.convs[str_edge_type].explain\n",
    "\n",
    "    clear_masks(model)\n",
    "    for edge_type in hetero_data.edge_types:\n",
    "        str_edge_type = '__'.join(edge_type)\n",
    "        assert model.conv1.convs[str_edge_type]._edge_mask is None\n",
    "        assert not model.conv1.convs[str_edge_type].explain\n",
    "\n",
    "    model = to_hetero(GraphSAGE(), hetero_data.metadata(), debug=False)\n",
    "\n",
    "    set_hetero_masks(model, edge_mask_dict, hetero_data.edge_index_dict)\n",
    "    for edge_type in hetero_data.edge_types:\n",
    "        # Check that masks are correctly set:\n",
    "        str_edge_type = '__'.join(edge_type)\n",
    "        assert torch.allclose(model.conv1[str_edge_type]._edge_mask,\n",
    "                              edge_mask_dict[edge_type])\n",
    "        assert model.conv1[str_edge_type].explain\n",
    "\n",
    "    clear_masks(model)\n",
    "    for edge_type in hetero_data.edge_types:\n",
    "        str_edge_type = '__'.join(edge_type)\n",
    "        assert model.conv1[str_edge_type]._edge_mask is None\n",
    "        assert not model.conv1[str_edge_type].explain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
